{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHPxPfQmrra3J9+t7Ba+sj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkhar21/ML_4/blob/main/Facial_Recognition_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.1 Kaggle"
      ],
      "metadata": {
        "id": "9RVsYAxRz6he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrTlVuSI1qzV",
        "outputId": "d82a28ab-a85f-4194-9b1d-181fe6057001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "0FEI5Yp71tqk",
        "outputId": "d9f7dda9-7e4b-4b8b-fabf-e35dcbb2d41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-544aac1f-52a2-4f6e-ba6b-c2364d4c5123\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-544aac1f-52a2-4f6e-ba6b-c2364d4c5123\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"nkhar21\",\"key\":\"5be6dca82ee543f5a1e380f0fccfe96d\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle/\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "w_d8XUGP1wE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TijV8sHD10lW",
        "outputId": "bf4048fd-c1b5-4803-8244-6c9d2a21faf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 82% 234M/285M [00:00<00:00, 623MB/s] \n",
            "100% 285M/285M [00:00<00:00, 645MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-YiQ89N16DY",
        "outputId": "552b2acc-f5ac-41c1-9fbb-fd6acd4d5363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "example_submission_df = pd.read_csv('example_submission.csv')\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "face_data_df = pd.read_csv('icml_face_data.csv')"
      ],
      "metadata": {
        "id": "nBwZl7_m3W0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sjmKpsFX6cTM",
        "outputId": "61ee880b-e8b5-4b88-a19b-c46b38396dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              pixels\n",
              "0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...\n",
              "1  156 184 198 202 204 207 210 212 213 214 215 21...\n",
              "2  69 118 61 60 96 121 103 87 103 88 70 90 115 12...\n",
              "3  205 203 236 157 83 158 120 116 94 86 155 180 2...\n",
              "4  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3aea07dc-86f5-4a55-bddf-61f286374870\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>254 254 254 254 254 249 255 160 2 58 53 70 77 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156 184 198 202 204 207 210 212 213 214 215 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69 118 61 60 96 121 103 87 103 88 70 90 115 12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>205 203 236 157 83 158 120 116 94 86 155 180 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aea07dc-86f5-4a55-bddf-61f286374870')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3aea07dc-86f5-4a55-bddf-61f286374870 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3aea07dc-86f5-4a55-bddf-61f286374870');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-be008a0d-cec0-460c-9a4f-841ce158ab00\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be008a0d-cec0-460c-9a4f-841ce158ab00')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-be008a0d-cec0-460c-9a4f-841ce158ab00 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 7178,\n  \"fields\": [\n    {\n      \"column\": \"pixels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7092,\n        \"samples\": [\n          \"21 12 14 13 12 11 10 10 5 0 57 126 138 131 150 151 144 135 126 125 117 121 130 122 117 131 135 138 127 121 114 114 110 92 84 104 102 64 17 8 13 12 12 12 14 14 12 14 21 12 14 13 13 11 10 6 9 55 126 132 125 121 134 148 133 123 122 122 121 116 124 120 115 122 132 132 119 113 106 116 103 102 80 77 88 90 55 6 11 11 12 12 13 13 13 15 22 11 12 11 9 10 7 6 28 94 115 107 116 132 138 135 132 126 126 126 123 116 115 120 109 111 123 128 123 114 108 114 107 94 98 70 67 83 75 30 6 12 11 13 12 10 13 14 23 10 12 11 11 7 10 22 48 57 84 118 134 143 141 135 135 132 130 124 121 113 109 117 111 116 132 137 135 132 107 98 109 85 75 77 53 62 88 59 24 6 12 13 12 11 12 14 22 10 14 11 10 7 29 44 52 65 133 142 140 144 143 141 137 133 128 121 114 104 101 102 103 113 135 149 143 139 133 113 111 105 64 62 76 44 81 90 49 20 10 13 13 13 13 14 21 11 13 12 9 7 38 46 44 117 158 148 146 141 140 136 131 131 126 121 110 96 98 97 103 121 134 146 146 136 147 132 128 109 75 46 67 78 43 104 65 46 15 13 14 14 14 14 21 11 13 12 15 27 26 1 64 158 149 149 144 136 135 134 130 125 120 119 110 105 104 100 104 118 129 141 133 114 118 126 116 104 92 68 36 72 48 63 82 47 30 10 16 15 16 17 23 12 15 12 26 27 12 23 134 152 150 152 145 135 132 131 132 127 123 121 115 109 112 113 115 127 135 140 136 120 113 117 117 95 81 71 47 39 49 35 80 44 37 16 15 16 17 18 25 13 16 13 26 12 10 80 159 146 152 154 144 143 137 138 140 140 133 124 121 106 115 128 130 143 144 140 139 123 118 123 124 105 83 76 65 41 40 32 71 55 37 24 14 17 18 19 26 15 14 13 21 3 10 130 166 164 171 163 151 164 153 150 148 142 133 121 122 115 118 126 133 146 152 142 143 135 122 123 122 108 94 86 84 71 34 26 55 62 45 31 15 17 18 19 27 16 17 18 21 0 38 158 163 168 162 160 153 148 152 148 143 138 123 116 113 120 119 126 142 152 139 133 133 123 124 128 117 106 88 85 83 89 62 39 59 57 49 43 17 18 18 20 27 18 14 29 21 0 63 168 165 171 168 153 153 151 143 140 134 127 113 111 113 127 126 140 158 146 145 120 109 114 97 95 93 100 87 74 69 85 111 92 81 65 55 62 24 20 21 22 29 19 17 35 14 0 87 174 167 168 162 159 165 156 145 139 135 126 115 112 125 123 111 133 142 143 129 125 104 103 91 86 71 76 86 86 69 69 90 138 122 92 71 66 28 19 23 24 29 18 21 17 8 3 124 177 170 168 166 171 164 156 151 152 148 139 128 111 116 98 93 108 113 122 116 122 114 95 76 70 53 57 57 51 63 53 47 61 110 124 86 73 33 21 25 26 30 20 23 17 7 14 151 176 173 174 161 149 141 149 144 144 139 138 132 108 89 82 92 115 125 118 123 95 58 43 27 36 38 33 41 47 17 15 20 28 26 79 87 70 41 21 25 26 33 23 25 21 5 32 166 165 159 157 140 127 111 105 99 91 86 94 106 93 71 78 108 114 115 109 107 56 43 64 66 69 73 51 64 31 37 68 44 47 59 40 73 67 48 24 25 26 36 26 24 22 5 49 166 145 146 148 125 112 78 68 97 112 75 76 70 53 39 43 79 89 114 107 115 109 130 134 119 97 83 68 57 44 88 111 62 52 62 38 61 74 48 24 27 29 38 26 26 25 4 52 115 85 121 151 135 107 64 29 92 145 129 107 44 30 28 74 86 120 135 126 105 105 146 136 132 93 57 57 38 53 100 104 57 43 66 37 56 86 66 29 26 29 36 25 24 16 21 61 78 53 54 117 151 96 31 56 144 145 122 75 61 71 75 79 92 120 128 122 87 71 136 156 109 72 34 51 40 19 20 44 56 58 56 40 63 85 74 29 21 27 41 27 20 67 71 64 144 133 104 118 132 106 65 45 62 18 22 51 38 71 84 48 123 145 124 110 77 57 111 138 108 56 47 78 62 40 48 32 53 66 30 33 57 82 81 32 25 29 40 21 40 164 52 0 111 120 53 111 147 86 72 94 127 78 61 60 75 91 95 95 160 160 116 85 54 50 58 79 85 51 65 89 94 39 76 72 67 53 20 39 48 71 80 32 25 28 38 16 77 171 82 10 32 14 41 160 158 86 56 93 139 122 103 103 102 107 117 125 116 111 83 58 52 51 56 55 60 64 61 68 67 81 95 74 69 36 24 43 46 71 72 24 25 27 41 22 72 149 108 13 14 66 112 169 129 94 93 99 143 143 127 133 101 134 142 132 96 65 51 49 51 61 62 60 64 66 55 55 49 81 79 41 35 21 30 45 54 94 57 21 27 28 42 29 17 116 143 44 0 68 151 143 114 118 116 111 166 168 147 132 142 158 120 97 63 48 47 48 48 59 61 61 59 61 59 48 66 71 59 63 32 13 23 34 74 90 39 22 28 27 45 32 22 51 161 126 13 71 183 146 120 123 121 83 125 176 141 146 152 106 75 66 47 40 49 51 47 52 59 63 67 60 52 51 82 81 78 52 15 18 29 48 85 79 20 23 27 27 44 30 30 12 79 193 129 110 188 148 101 126 136 110 71 129 164 147 133 114 97 72 53 53 54 50 50 56 59 56 60 57 57 55 90 100 61 19 17 31 45 60 95 57 18 23 26 27 42 30 31 26 5 79 166 152 185 142 107 146 120 81 51 68 167 170 165 154 131 95 74 91 74 53 51 55 59 61 63 55 54 53 65 56 28 23 24 46 62 74 94 32 11 23 26 27 41 31 32 28 21 6 8 119 157 86 63 69 44 31 22 43 129 146 148 140 113 77 76 113 89 52 49 52 57 68 66 57 47 49 59 55 36 41 50 59 58 53 79 132 21 18 25 26 43 31 33 29 25 22 3 42 109 44 22 6 0 9 24 77 133 143 145 132 110 70 69 101 88 52 46 55 63 73 66 52 46 47 63 59 48 62 57 57 42 42 148 213 57 11 25 24 43 30 32 28 26 21 16 0 66 136 97 33 58 93 119 132 133 132 151 136 115 84 79 95 84 55 47 49 60 71 65 55 46 50 65 71 62 60 56 42 31 127 195 172 27 16 27 23 44 29 31 32 27 23 18 2 37 177 187 165 166 175 175 148 129 133 149 140 124 108 86 79 75 61 49 44 52 64 63 53 42 47 53 60 62 56 41 32 122 171 180 89 2 22 28 29 43 32 31 31 28 26 20 4 36 193 199 191 181 157 156 140 104 134 125 141 144 125 91 80 77 59 49 43 47 58 67 50 40 39 41 47 57 38 36 120 160 161 130 9 10 22 25 29 44 33 31 34 29 25 21 1 58 199 168 156 89 78 81 66 33 69 98 134 161 138 94 81 75 52 44 39 46 53 63 50 36 30 35 42 36 40 130 155 141 146 54 0 16 20 24 28 43 33 33 32 31 25 21 10 13 143 137 57 27 27 22 21 22 22 43 111 163 134 96 78 67 49 40 42 47 55 64 46 33 28 30 28 29 134 155 137 143 98 0 11 14 19 22 25 43 32 32 30 28 26 19 17 2 25 83 20 29 49 93 129 97 70 95 92 133 123 86 67 57 42 39 46 50 52 58 38 26 26 25 12 112 158 137 137 134 35 1 14 16 20 21 25 44 33 33 32 29 25 22 19 16 0 55 140 161 171 152 92 42 68 114 79 111 118 78 63 52 44 42 46 51 48 48 34 26 22 6 83 160 140 139 148 70 0 13 13 18 21 22 26 42 33 33 31 29 27 24 21 17 4 27 163 122 70 44 12 28 91 100 92 147 146 110 72 46 42 43 46 45 46 39 28 27 7 64 156 142 145 152 123 11 10 18 20 23 26 28 22 42 33 34 31 28 26 23 24 19 10 4 93 100 17 46 84 99 124 133 151 162 149 132 94 40 35 39 41 42 39 33 27 12 44 150 147 148 143 138 44 8 20 25 30 34 44 32 26 43 31 33 31 28 25 23 23 21 14 6 16 107 137 164 188 177 159 158 159 148 108 74 51 38 35 39 42 38 31 26 20 22 126 144 136 134 144 87 6 23 28 36 41 51 47 28 52 40 30 32 31 27 24 23 21 20 15 13 3 23 146 190 177 165 164 152 147 122 64 31 40 41 40 40 40 36 29 26 10 79 143 131 136 140 138 36 21 29 38 45 53 62 28 49 62 39 32 31 30 27 23 23 19 19 16 12 13 0 86 183 164 152 137 138 133 76 40 43 40 42 41 42 42 38 32 23 36 122 129 134 137 155 83 16 32 34 45 50 62 47 30 64 65 40 31 29 29 26 23 24 22 20 16 15 11 0 59 166 132 111 116 101 78 48 61 50 42 43 42 43 45 41 38 24 86 134 130 132 140 133 37 32 36 41 49 62 72 22 51 66 65 41 30 29 28 26 24 23 24 21 17 16 14 6 18 136 104 59 84 59 63 73 55 38 45 47 46 44 48 51 25 46 128 131 127 123 145 81 26 38 45 52 63 71 53 31 71 67 68 40 28 29 29 28 27 25 21 19 19 16 13 10 2 32 56 54 59 65 66 56 40 38 49 49 50 52 56 39 23 102 136 127 127 142 130 38 39 46 53 50 43 35 23 44 73 71 70 39 29 30 30 28 27 24 21 21 18 16 14 11 10 6 5 11 9 30 60 55 46 42 55 59 57 59 48 16 75 132 128 136 148 174 80 36 44 32 28 24 18 18 18 21 55 76 73 40 29 30 30 29 27 24 23 21 18 17 16 15 12 15 14 11 13 9 33 67 68 58 67 71 67 56 14 56 127 121 141 165 186 160 39 35 32 29 17 13 17 18 24 18 25 70 79 38 28 30 29 28 26 24 23 21 18 20 15 15 14 15 15 15 15 17 11 21 50 79 86 81 72 21 44 118 116 126 163 179 200 96 28 42 25 30 52 35 15 18 21 27 13 49 80 37 27 29 31 27 26 25 22 21 18 19 17 15 16 16 16 16 16 16 16 11 5 20 74 102 18 24 104 115 117 152 175 194 174 44 117 103 26 30 42 34 14 16 17 24 13 37 79\",\n          \"18 15 24 21 22 28 27 27 43 75 92 98 108 123 135 147 148 145 154 167 165 167 162 150 153 166 170 172 169 166 160 151 145 136 131 123 119 119 101 60 33 29 23 27 22 13 11 10 18 24 31 26 28 24 24 36 60 86 96 101 109 125 137 143 149 151 159 167 168 167 160 163 159 161 165 162 166 165 158 149 139 130 124 114 116 119 109 73 38 28 23 24 17 19 23 19 25 20 34 27 25 26 32 49 71 90 96 105 109 120 130 141 148 153 159 160 168 166 165 162 155 154 160 161 160 158 158 150 140 128 116 112 112 112 103 78 53 32 30 21 14 14 26 28 16 13 26 19 20 21 40 65 74 91 99 108 112 118 126 143 152 157 158 160 167 166 164 163 155 156 161 159 155 155 153 146 138 125 113 108 110 109 105 90 66 37 30 23 16 7 10 22 10 16 21 21 21 30 42 70 86 91 100 105 109 113 120 139 148 153 155 166 164 162 163 160 158 158 159 155 156 153 148 141 132 120 111 107 106 104 101 94 72 51 33 22 16 4 8 21 15 25 22 20 16 40 57 75 81 91 99 103 104 112 117 128 142 151 160 163 161 161 159 154 154 157 159 157 150 142 139 135 129 127 124 118 111 104 99 97 87 69 42 20 16 5 8 20 15 23 28 23 21 47 75 74 88 96 98 100 101 107 113 123 135 147 156 158 163 163 155 147 153 157 154 155 151 143 137 134 131 124 116 110 108 104 106 92 90 78 44 20 15 7 12 18 14 14 20 16 28 60 70 82 89 90 95 100 99 99 106 122 134 144 156 162 164 162 159 152 155 157 155 154 148 145 143 141 139 127 116 111 111 107 100 91 91 81 49 18 13 10 10 13 13 9 13 14 25 57 73 88 91 90 95 102 104 108 114 125 139 150 158 167 166 165 166 163 158 157 156 154 155 149 147 148 144 131 125 125 115 105 111 101 89 83 53 17 12 10 6 5 9 10 17 17 20 59 73 82 87 92 106 93 106 118 125 140 158 165 165 165 166 166 165 163 158 156 156 156 162 161 153 158 155 132 115 102 89 75 88 102 91 79 53 14 14 11 8 5 10 14 18 14 22 58 75 77 80 102 89 66 86 110 129 150 168 171 171 168 173 173 165 162 156 155 162 165 167 161 161 146 120 96 73 58 53 61 59 75 97 78 53 14 14 12 11 8 12 14 18 14 23 57 75 78 94 76 54 62 63 63 81 98 109 109 133 160 170 178 172 164 160 161 167 167 158 149 120 86 64 46 33 49 69 77 80 69 84 82 57 16 13 12 12 12 16 9 13 10 24 58 71 80 71 53 69 86 87 71 56 55 64 91 109 129 154 165 168 163 160 162 169 164 158 132 99 83 57 63 104 130 137 127 112 97 88 83 63 19 13 11 13 15 21 6 9 14 22 57 72 76 82 106 124 141 155 153 133 104 86 100 124 135 141 158 166 161 156 156 167 164 156 126 113 103 99 121 131 125 119 110 117 108 92 82 69 27 11 10 11 15 25 8 6 11 23 61 73 81 99 119 134 137 140 142 148 148 137 126 123 131 136 150 153 154 151 149 153 151 134 111 101 115 130 137 138 139 119 98 93 91 92 85 72 38 10 7 9 14 23 9 7 10 22 62 72 83 101 108 108 114 126 156 142 133 142 141 132 125 127 135 149 160 148 145 145 134 112 100 118 134 144 141 132 141 120 98 80 80 87 81 76 47 11 6 7 14 21 10 9 8 30 66 72 84 98 99 86 83 101 112 96 101 115 118 130 136 127 129 148 169 160 150 142 118 100 114 134 127 137 141 127 123 122 104 89 78 83 85 78 59 21 5 6 21 20 7 8 8 38 70 76 89 105 100 81 72 77 80 83 93 75 98 112 141 148 118 130 167 166 151 136 104 88 121 131 104 129 116 71 66 37 57 37 66 99 95 84 68 33 3 2 17 20 4 4 4 42 72 77 95 108 103 80 33 124 61 61 55 132 166 101 111 146 110 112 140 154 146 129 103 89 110 95 54 145 136 25 40 68 102 50 99 112 92 83 71 41 2 4 14 16 3 3 5 42 72 80 95 103 114 124 93 104 119 45 44 129 101 117 128 123 106 112 128 147 151 130 106 94 96 90 99 92 96 71 75 85 65 103 126 115 93 80 72 44 3 7 12 18 4 4 3 37 72 78 87 93 106 121 129 113 119 122 116 105 127 144 136 104 106 114 130 152 165 139 106 97 101 110 117 105 97 104 106 100 106 128 131 115 95 81 71 44 4 11 12 22 7 4 2 29 69 75 85 89 106 121 129 137 134 131 118 108 106 105 107 111 112 116 133 153 167 142 116 110 113 118 118 119 117 111 114 122 133 136 129 115 95 81 68 39 3 12 8 18 9 4 4 19 64 75 83 88 102 122 130 125 125 116 114 121 122 126 132 121 123 123 137 153 169 141 123 126 123 126 128 126 129 130 135 138 141 135 125 113 92 79 66 30 4 10 4 26 9 2 4 11 57 74 81 91 106 118 134 144 151 148 142 139 138 154 143 123 123 123 131 154 175 145 125 120 120 122 132 134 133 138 147 149 137 129 124 112 89 74 62 18 8 7 2 29 9 3 4 3 44 72 82 92 109 122 135 153 159 162 165 159 162 165 140 120 113 118 134 157 175 147 130 113 111 115 124 133 135 147 158 161 142 131 125 104 83 76 54 9 9 4 3 30 11 4 2 0 32 69 81 89 110 128 144 155 175 191 178 162 174 172 127 113 105 122 134 156 173 164 139 116 108 107 120 132 136 139 150 156 141 121 113 92 78 75 44 7 6 2 3 33 13 4 2 0 22 62 76 89 106 121 139 156 180 177 171 180 175 172 136 99 100 119 140 154 165 158 138 120 114 109 122 129 134 142 146 147 136 119 105 86 74 67 40 5 3 3 3 29 11 5 2 0 11 57 74 88 103 117 131 148 170 175 176 182 177 185 119 90 107 135 170 171 157 156 140 119 120 111 121 133 132 146 148 146 135 117 99 81 71 64 38 2 2 3 4 26 13 7 2 2 4 48 73 84 102 115 126 138 157 173 179 182 177 160 99 121 155 163 185 183 167 162 134 138 139 112 109 131 131 141 141 136 128 107 87 75 68 61 34 1 2 3 5 25 15 10 2 4 0 38 73 76 93 108 119 128 143 162 173 166 172 147 106 141 104 88 132 161 150 135 87 82 127 107 104 125 135 135 136 129 118 93 75 68 61 59 31 1 3 3 5 22 18 10 4 4 0 30 73 75 81 92 102 118 136 146 159 170 168 143 127 105 96 102 123 128 119 105 68 78 100 102 121 119 130 131 122 112 101 79 64 60 56 60 27 1 5 4 6 23 17 12 4 3 0 25 76 78 75 81 89 107 123 129 146 156 134 129 126 117 116 107 114 146 128 88 74 73 71 108 121 115 117 123 108 94 81 68 59 56 59 65 26 3 5 5 7 25 18 13 5 3 0 20 76 85 76 79 84 92 108 116 131 127 114 113 109 96 77 65 66 105 97 74 58 51 68 104 116 111 107 107 98 86 72 63 59 58 63 61 20 4 6 6 8 26 19 12 8 3 0 11 68 89 80 75 80 84 95 105 111 103 102 101 89 64 54 58 60 77 65 54 50 46 56 84 96 96 96 94 87 80 69 58 57 60 65 54 11 8 5 8 8 27 19 11 10 4 2 4 54 82 86 76 72 80 87 89 83 76 76 68 63 47 43 55 61 58 57 65 61 52 49 61 59 65 71 80 81 78 65 58 61 62 64 37 6 9 5 11 11 25 19 11 11 6 3 1 28 74 89 85 72 77 81 85 70 54 57 52 59 72 94 119 129 127 126 128 120 107 90 83 61 53 52 62 74 73 60 60 64 63 54 13 8 10 6 12 12 18 18 12 10 8 3 4 3 41 87 87 76 73 79 82 58 63 77 84 122 126 130 139 137 135 129 123 121 118 115 110 92 73 57 52 67 69 56 61 64 61 24 1 14 10 8 15 10 13 19 18 11 9 4 4 3 7 53 71 77 71 71 81 67 83 104 111 101 92 99 106 113 117 111 106 92 84 80 84 95 92 80 60 66 64 57 61 59 31 1 9 15 6 10 16 8 8 20 19 12 12 5 4 4 4 47 74 67 73 66 77 83 88 106 87 72 90 75 62 68 69 59 68 64 54 56 58 78 86 80 62 61 57 57 58 34 1 3 11 14 9 14 15 8 10 27 24 10 12 8 5 5 3 42 106 80 64 73 71 76 88 102 114 105 108 135 107 92 91 95 92 96 98 100 88 94 83 67 61 59 58 56 51 17 2 6 14 14 8 19 15 7 15 26 20 13 16 10 5 6 2 34 96 113 77 67 70 72 80 92 101 115 127 131 150 147 136 140 124 128 116 104 97 75 68 64 60 61 57 52 54 14 4 8 16 10 14 24 9 9 16 40 22 11 14 12 5 6 3 29 89 110 105 69 64 76 80 83 86 94 112 134 135 156 161 158 157 141 110 103 72 61 63 63 61 58 50 65 50 8 5 8 17 10 20 25 6 9 11 29 24 14 14 14 8 7 4 26 86 108 111 102 68 72 80 80 83 84 79 89 100 103 111 110 113 102 88 73 67 66 66 65 60 50 66 73 38 7 8 11 22 13 26 20 5 13 10 32 26 14 11 19 11 9 6 23 78 109 111 114 107 71 75 91 94 94 102 102 100 107 103 97 89 90 93 87 82 77 75 63 52 74 81 64 27 7 12 16 21 14 30 21 5 16 12 36 29 15 10 18 11 10 8 18 73 114 115 114 116 111 73 81 102 106 116 136 162 162 150 135 127 123 114 97 85 86 73 55 80 91 81 56 18 10 12 20 20 20 30 11 9 28 11 31 26 19 7 10 13 10 10 13 60 112 120 121 117 125 118 83 91 110 115 121 134 138 125 117 122 111 102 93 86 78 56 71 99 88 81 45 16 16 17 25 16 30 29 5 18 36 15 27 20 20 9 7 13 9 8 9 40 101 119 123 121 123 129 120 85 79 98 108 103 105 105 108 106 99 96 81 65 53 54 83 97 91 77 30 16 13 19 23 14 36 24 3 31 31 21 40 18 19 12 7 14 14 10 8 26 95 117 123 126 123 122 119 109 86 78 82 82 88 91 90 87 84 69 49 49 51 60 86 98 95 58 22 19 11 22 19 16 33 12 5 39 26\",\n          \"172 156 68 0 5 15 47 81 101 110 115 120 124 127 136 144 151 156 157 159 161 160 166 170 177 177 168 152 141 134 120 106 90 79 71 52 51 41 32 30 44 35 17 2 1 1 1 0 155 130 55 0 5 23 61 89 106 117 122 124 128 132 138 148 159 160 159 164 169 170 174 183 191 186 173 156 142 134 126 114 109 91 73 62 57 65 54 44 41 37 23 11 0 1 0 0 121 102 65 1 4 36 79 96 111 119 126 129 130 135 142 152 159 159 161 166 173 176 180 184 187 184 171 158 152 145 133 126 119 111 99 94 81 60 54 67 59 45 36 27 9 2 0 0 93 92 74 7 6 47 83 100 110 120 125 129 135 137 143 152 157 159 161 165 171 172 173 175 175 172 163 154 152 150 141 132 126 117 109 98 90 91 79 71 73 68 59 44 25 11 0 0 90 90 76 11 9 53 88 98 111 121 124 128 135 139 144 150 155 161 164 164 166 169 171 169 169 168 167 162 158 150 145 142 139 131 119 105 89 89 91 83 78 74 69 47 36 20 8 0 88 88 73 13 5 50 88 95 108 117 122 126 130 135 140 146 154 161 165 164 162 165 168 168 167 169 169 169 169 160 147 147 150 142 129 120 108 101 99 106 97 88 81 64 44 30 15 3 84 85 77 19 0 47 88 95 104 115 122 124 127 131 135 142 151 159 162 162 162 160 161 165 167 167 171 174 171 164 156 146 147 147 140 128 117 113 109 111 116 113 104 82 49 36 19 6 81 82 81 34 1 53 89 94 101 111 120 123 128 130 135 139 146 154 157 159 158 156 159 166 174 179 178 180 170 143 119 101 83 80 87 103 114 118 115 115 113 114 111 97 67 41 26 21 80 77 82 52 4 56 91 98 101 108 116 124 128 129 129 136 142 145 148 152 151 152 154 159 155 140 128 114 101 89 96 100 99 96 84 72 73 101 115 113 114 115 115 104 73 43 36 33 78 76 76 65 17 61 95 100 101 110 119 120 125 126 127 129 134 138 141 144 144 146 133 107 82 63 62 65 92 120 147 151 147 137 130 117 96 79 97 113 116 117 113 103 76 45 39 35 75 74 73 71 38 70 98 100 109 114 119 121 124 126 128 129 131 133 138 141 143 135 95 69 72 76 90 110 128 139 144 145 140 128 119 111 107 103 94 108 117 118 113 103 88 48 44 50 73 71 71 70 51 76 104 93 86 81 77 80 96 111 125 126 129 134 139 141 137 125 101 92 92 95 108 123 139 152 157 157 146 130 109 94 89 95 99 106 112 116 112 106 89 59 43 50 70 69 69 69 60 81 72 35 33 37 42 51 52 73 110 121 123 127 135 136 132 121 109 92 89 104 115 127 132 119 104 96 91 94 89 82 79 91 105 111 113 113 114 111 97 79 49 47 68 67 67 65 66 49 31 45 56 64 68 67 67 72 91 109 115 120 129 134 129 119 103 88 94 103 107 87 53 29 30 15 21 35 41 55 75 95 113 119 117 116 118 116 101 79 63 52 66 66 65 64 59 51 81 96 99 104 106 103 97 86 75 82 98 110 120 129 131 119 103 90 88 95 77 29 7 5 4 5 6 1 0 22 74 100 121 127 125 122 119 116 103 79 57 62 64 63 62 61 59 75 86 97 109 119 124 125 123 118 98 66 71 99 118 131 138 127 113 101 88 96 39 0 2 3 1 40 80 58 72 84 110 128 132 130 128 124 118 112 97 79 58 58 62 62 61 59 58 63 82 94 99 100 100 105 106 108 114 99 62 80 118 144 156 144 131 127 111 87 21 45 56 14 36 82 114 142 125 124 140 142 135 129 128 123 116 106 91 77 62 56 61 60 58 55 55 50 55 46 31 31 40 44 56 85 103 110 88 70 111 151 168 159 147 152 144 89 72 101 83 88 106 126 122 110 118 140 152 150 141 132 126 122 114 102 87 77 63 54 59 58 56 53 52 47 20 5 3 0 6 10 17 52 76 112 112 84 114 153 169 166 151 152 158 143 128 110 92 86 87 90 98 125 146 153 163 158 144 133 127 119 114 104 89 76 64 54 58 56 54 52 49 24 0 0 2 17 10 5 47 147 67 86 131 93 119 151 163 160 150 145 151 158 158 149 135 122 121 132 146 155 152 163 180 169 145 133 127 117 112 104 89 75 66 59 55 55 53 50 46 25 19 15 24 55 15 30 95 137 132 133 129 99 123 148 162 156 146 139 146 158 164 166 166 163 161 162 161 156 158 172 190 172 146 131 122 117 107 98 86 72 66 59 54 53 51 50 43 66 93 69 86 73 76 105 112 104 116 130 123 103 122 148 165 156 145 141 147 157 164 167 165 165 165 161 155 155 167 186 194 168 144 130 119 111 101 94 83 71 67 61 54 51 50 49 42 67 107 82 70 76 73 73 82 102 124 126 112 105 126 152 165 161 149 149 156 160 165 166 168 169 167 166 165 167 182 191 191 170 145 127 115 106 95 88 79 71 70 65 53 52 50 49 44 60 107 117 100 84 89 96 112 129 131 120 107 107 129 149 160 158 148 149 161 164 160 160 168 171 172 177 182 185 183 176 169 155 140 124 109 100 91 83 76 72 69 65 54 54 52 49 46 58 102 119 135 138 136 134 137 138 128 116 105 106 127 146 153 147 139 140 145 150 138 134 139 143 149 152 156 157 157 153 145 137 128 117 105 97 86 77 78 75 71 62 57 56 54 52 47 54 97 116 129 136 143 148 147 137 128 118 104 100 127 143 148 147 139 130 132 136 130 130 139 129 112 102 116 126 129 129 126 119 114 108 97 88 81 79 81 77 71 63 60 58 57 54 50 52 89 111 124 137 151 159 150 135 130 118 97 99 130 147 155 157 147 137 147 158 145 115 142 153 136 106 85 96 108 111 111 107 100 94 85 77 78 84 85 81 71 64 62 59 58 56 52 51 82 106 121 137 156 159 147 135 125 109 100 98 132 160 178 175 153 159 170 145 110 94 144 153 147 159 133 97 94 98 99 95 92 89 77 77 84 90 91 82 72 66 63 61 60 57 55 50 70 100 116 126 145 152 141 129 117 109 107 94 119 142 149 135 131 115 59 26 56 129 158 154 152 144 154 144 109 97 94 90 89 82 80 88 96 97 94 82 72 66 64 63 62 59 56 52 59 89 105 118 124 129 128 119 106 100 99 83 88 110 115 116 85 28 64 116 149 161 160 161 163 152 138 145 133 113 98 91 90 91 95 98 108 104 95 79 70 63 64 64 62 61 57 54 52 69 91 103 112 113 115 114 107 78 60 26 37 61 60 48 42 105 160 154 155 159 158 158 156 159 149 138 142 126 109 102 104 104 105 113 113 106 94 73 67 57 64 63 62 62 59 57 53 49 71 89 95 102 105 105 111 75 70 66 59 62 65 69 114 137 145 139 142 146 144 145 144 149 155 145 137 131 121 122 121 115 118 119 117 107 88 68 63 49 64 63 63 62 60 57 54 48 46 68 80 90 98 107 112 97 94 104 108 124 142 142 134 136 138 137 139 142 141 137 140 139 138 125 121 128 127 132 126 122 125 121 119 106 83 65 56 43 64 64 62 60 59 56 53 52 44 45 64 77 90 106 107 106 111 112 112 117 121 122 135 124 118 119 123 127 129 127 122 118 103 110 125 125 128 130 127 122 123 124 117 97 73 60 46 38 63 62 60 58 58 56 54 51 50 41 48 70 88 101 104 100 104 106 97 93 97 99 110 103 86 69 73 78 80 91 89 82 94 113 130 130 129 125 122 125 125 120 109 86 66 53 38 43 60 59 59 57 56 55 53 51 49 49 45 70 91 94 97 93 100 100 102 104 102 81 77 90 110 103 129 102 78 102 114 132 137 133 135 129 125 122 118 123 121 115 99 75 56 42 34 54 60 59 57 56 55 53 52 50 47 50 47 64 99 98 82 75 74 82 90 69 50 77 87 104 161 166 156 154 170 170 155 135 138 142 140 130 124 119 115 116 115 107 87 63 48 34 41 66 58 56 54 53 51 51 51 49 46 47 51 56 90 111 86 61 57 63 60 86 112 139 151 153 157 157 148 145 153 136 122 129 141 139 139 132 122 115 111 112 108 96 75 55 38 31 59 75 55 53 52 50 49 50 49 47 46 44 48 52 68 106 110 63 72 95 109 130 140 141 145 143 144 140 130 131 132 125 123 123 131 140 143 136 119 111 107 106 98 85 65 45 31 44 76 82 56 54 51 50 48 48 47 45 45 44 42 52 56 83 116 94 68 98 102 99 113 125 126 123 121 117 117 122 118 116 120 121 122 139 147 137 120 109 100 99 91 76 53 34 32 69 87 86 58 55 52 50 48 47 45 44 43 42 40 42 54 60 95 110 88 80 86 91 95 99 99 92 88 95 103 101 97 101 111 116 122 139 143 131 111 102 99 98 85 62 40 28 59 88 95 91 58 57 53 51 49 48 46 44 41 41 40 35 43 51 66 104 98 81 73 74 78 80 83 92 99 100 95 92 99 110 115 118 130 146 134 116 99 99 101 93 75 49 28 47 86 95 100 97 57 56 54 52 48 47 46 42 40 38 37 35 33 43 48 84 106 94 81 66 64 68 75 90 98 96 104 117 134 141 140 133 142 145 119 105 95 100 100 84 60 33 33 82 98 102 103 100 55 54 52 51 48 46 44 41 38 35 34 34 32 32 42 56 98 107 106 94 86 81 86 93 105 123 143 156 157 160 154 145 157 138 116 104 95 101 93 69 39 21 74 104 106 105 106 99 53 52 50 48 46 44 42 39 37 33 32 32 31 31 34 44 73 108 114 118 118 124 132 141 151 159 162 162 167 166 157 159 149 127 116 98 92 92 74 46 14 59 106 102 106 110 103 100 50 50 49 46 45 44 41 38 35 33 30 29 30 31 31 33 53 96 110 121 137 142 143 146 153 159 164 167 168 164 164 150 125 115 107 87 83 77 48 12 33 101 96 106 115 107 105 104 49 48 47 46 44 43 40 37 35 32 29 28 29 30 29 27 30 74 114 107 131 147 145 150 155 158 156 160 158 158 142 113 106 104 88 70 67 47 14 15 84 108 116 118 114 110 109 107 50 49 46 46 44 43 42 39 36 32 29 28 28 27 27 26 23 35 107 110 105 140 145 145 144 136 135 138 138 129 104 89 98 85 57 52 40 13 8 57 114 120 121 117 115 115 113 105\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jlUWLkVq6sJx",
        "outputId": "a70b16fe-2bb1-4a2a-ca5a-a1483874b856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   emotion                                             pixels\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75c7e4f3-1a91-402c-a6ba-9979f901ce14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75c7e4f3-1a91-402c-a6ba-9979f901ce14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75c7e4f3-1a91-402c-a6ba-9979f901ce14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75c7e4f3-1a91-402c-a6ba-9979f901ce14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-58a82b31-7f3e-4a2e-ad9d-3337f1bca73a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58a82b31-7f3e-4a2e-ad9d-3337f1bca73a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-58a82b31-7f3e-4a2e-ad9d-3337f1bca73a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 28709,\n  \"fields\": [\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pixels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27473,\n        \"samples\": [\n          \"165 165 164 140 83 23 18 19 14 17 10 20 32 28 24 40 62 75 78 85 53 41 60 70 77 96 102 112 103 127 156 165 177 163 168 142 130 119 70 95 105 64 39 41 54 51 33 28 164 163 157 138 72 21 18 15 13 12 15 21 41 41 37 59 79 86 92 93 57 40 63 80 104 122 106 107 110 138 164 183 179 173 172 141 131 127 85 52 67 72 64 60 50 56 42 28 167 157 163 133 36 19 13 12 13 11 15 25 50 51 58 80 97 105 96 92 62 40 69 110 131 133 109 98 119 151 179 188 181 173 164 145 133 127 95 55 55 67 67 67 54 61 52 37 167 157 164 109 20 17 14 14 14 13 18 23 44 59 80 98 110 104 84 90 80 61 97 136 143 142 109 98 128 157 180 183 178 171 159 144 144 130 97 66 55 61 80 65 57 61 57 42 162 162 155 68 12 15 14 15 13 13 20 22 46 65 96 113 101 91 88 95 96 98 125 150 151 144 108 107 141 168 182 184 179 176 160 141 141 132 108 83 58 54 77 65 47 52 56 44 157 168 144 41 11 12 15 16 11 13 14 29 61 69 112 116 91 98 109 114 121 127 144 160 163 156 116 112 147 179 183 186 176 171 164 148 146 137 114 98 67 54 68 57 37 34 41 52 164 171 105 14 15 11 18 18 13 16 16 41 64 81 128 101 101 115 116 126 145 149 157 166 169 168 135 122 148 177 179 187 177 167 164 155 147 138 123 109 77 51 51 47 38 20 22 56 159 173 70 8 13 10 22 23 13 14 19 58 65 119 125 115 129 121 129 141 150 159 164 168 180 178 156 145 158 174 176 180 179 168 161 160 150 142 131 117 86 47 46 37 34 19 17 57 160 161 51 12 10 16 30 26 14 11 43 71 108 130 116 132 133 130 136 151 156 162 171 175 182 186 181 174 174 181 169 180 183 168 161 160 152 143 134 123 91 47 43 37 37 26 20 33 161 141 43 4 11 21 40 21 14 21 59 93 110 95 104 116 122 133 142 156 162 168 175 180 186 191 189 185 185 188 177 173 174 168 160 156 154 150 136 128 104 52 22 40 49 39 30 18 172 121 30 14 10 21 31 24 9 41 83 86 81 85 86 78 91 108 127 145 164 172 173 182 195 199 194 188 187 187 191 179 172 171 162 153 151 151 141 128 110 60 22 16 36 47 33 17 151 52 34 18 14 22 23 15 25 82 103 96 105 104 98 93 81 85 98 113 150 171 170 179 191 194 196 192 192 199 194 183 176 168 161 159 153 148 147 135 119 67 24 14 18 27 30 26 47 20 21 12 17 20 23 11 71 111 112 107 120 128 127 135 125 98 95 102 126 153 162 167 175 186 189 187 191 197 193 188 182 170 161 159 158 156 156 149 134 71 23 17 15 18 24 21 27 20 15 14 17 19 15 43 106 120 109 111 119 133 139 142 148 139 128 117 110 128 146 157 166 177 179 175 172 172 178 182 178 171 155 137 139 143 146 156 149 87 25 18 13 15 27 32 49 35 13 14 16 18 19 90 126 120 106 117 104 89 85 101 130 142 141 133 126 128 145 154 161 171 173 164 156 150 147 144 137 136 125 104 96 101 111 124 141 109 31 15 16 13 18 28 23 17 12 14 19 10 51 115 128 127 100 75 50 57 88 37 62 102 124 137 129 132 144 153 161 170 169 159 149 140 132 122 120 108 93 92 95 98 103 104 117 105 48 22 14 13 15 19 14 14 16 14 11 20 86 120 131 139 113 93 89 108 126 26 51 55 50 127 132 126 137 151 167 174 168 158 145 140 141 140 136 132 133 138 137 128 118 118 110 95 63 33 15 14 18 30 57 28 10 16 12 46 104 121 140 145 144 120 123 136 125 97 62 35 78 103 128 126 133 144 163 174 169 156 149 146 148 148 146 153 166 159 148 146 139 130 126 115 76 43 22 13 11 19 52 17 14 19 19 69 115 124 141 149 155 145 127 128 142 148 158 137 126 86 129 126 129 149 170 175 162 154 141 137 132 118 109 102 112 128 139 137 133 131 124 116 98 64 34 14 15 16 18 9 21 25 33 86 110 126 142 144 153 156 144 136 137 135 132 133 133 120 144 126 129 153 174 174 154 142 121 123 100 95 24 70 76 43 75 115 129 122 123 118 107 88 66 41 14 16 26 13 15 33 45 94 108 127 141 149 155 161 161 151 151 153 142 141 140 145 141 126 135 158 174 165 147 127 140 109 90 127 43 38 38 54 74 55 94 123 121 122 114 101 90 67 21 18 24 11 22 35 58 96 112 128 137 150 160 165 167 163 164 168 164 163 156 154 136 130 145 164 171 157 139 137 156 117 122 133 119 99 96 123 125 79 72 95 112 121 123 114 102 85 36 15 23 16 22 41 74 94 113 127 138 153 158 162 168 172 172 170 171 166 154 144 138 137 153 170 169 154 142 144 156 150 149 137 140 149 151 136 133 125 117 108 114 130 132 123 106 96 55 15 31 21 17 42 80 92 113 130 144 156 160 171 177 173 169 167 167 154 146 145 140 143 157 168 168 155 151 151 159 162 157 156 143 135 132 136 135 129 138 144 138 139 139 128 107 99 67 15 28 19 18 38 82 91 112 132 145 157 162 173 175 171 169 165 157 151 143 144 140 144 164 170 165 155 158 154 159 172 167 165 170 166 159 156 152 150 149 150 146 143 139 129 111 97 70 23 23 16 13 29 83 91 107 130 144 156 162 167 167 167 165 159 153 145 139 139 136 146 167 168 158 151 158 156 160 176 180 174 173 176 174 169 162 159 160 156 149 145 137 125 109 92 65 28 18 15 14 30 90 91 103 125 139 149 153 155 155 153 149 140 130 122 124 130 134 150 164 159 155 151 154 157 159 172 179 174 172 174 173 172 169 167 163 157 151 147 137 124 102 90 55 22 18 16 13 29 89 91 99 122 132 139 140 139 135 131 132 129 126 130 130 132 143 159 165 152 148 143 143 155 167 175 179 179 175 172 171 171 172 168 161 154 149 146 135 122 96 86 55 31 17 18 21 50 101 92 93 111 122 130 128 126 121 121 127 121 117 141 140 130 150 179 185 162 147 136 133 140 161 178 182 182 182 178 176 176 174 167 156 150 143 141 129 113 90 77 62 53 14 29 78 110 104 107 91 97 112 120 118 118 130 143 140 118 94 122 136 124 137 158 175 158 145 141 141 134 142 158 174 183 182 182 180 178 174 166 155 150 139 132 126 105 83 68 67 90 26 74 134 104 102 120 114 108 112 117 119 127 140 147 146 138 95 57 66 85 109 121 133 135 141 146 148 142 127 130 145 167 177 179 179 176 168 161 152 147 135 128 119 96 78 55 101 113 53 122 104 64 112 126 132 125 125 129 135 134 132 135 137 135 129 126 101 73 74 84 85 90 114 136 141 125 128 142 123 138 163 169 169 163 159 155 147 141 129 121 111 91 68 75 131 97 128 123 39 54 110 126 137 136 134 138 135 129 124 128 134 134 139 143 148 156 134 103 97 87 66 76 94 115 145 148 130 116 135 152 155 151 150 148 138 131 119 111 103 84 61 109 119 127 119 58 10 62 110 125 136 144 139 140 140 135 127 119 126 137 142 142 153 174 174 155 161 177 149 134 134 151 161 158 159 133 111 132 144 141 140 139 130 121 111 103 97 76 72 99 108 125 56 19 23 53 104 128 135 145 138 144 148 111 75 57 68 79 93 100 120 155 166 167 166 161 158 153 157 153 155 154 155 149 123 106 122 136 129 130 123 113 100 106 102 72 79 108 124 100 31 19 19 48 100 126 138 144 130 140 144 105 44 49 47 53 62 62 67 92 131 154 161 159 146 158 149 146 138 140 151 141 129 116 110 117 119 118 103 96 107 118 100 79 114 128 132 67 23 23 13 30 86 122 141 148 133 140 140 135 102 105 128 123 127 98 95 94 92 88 86 88 102 121 135 144 145 142 138 135 130 128 116 111 114 109 106 113 128 126 97 89 123 100 67 20 19 15 16 8 66 116 134 147 137 137 135 136 108 103 152 187 169 150 178 197 163 162 109 96 73 59 71 83 102 120 126 128 136 132 127 126 124 122 125 133 134 130 81 30 36 70 23 7 22 12 22 13 47 104 128 143 137 138 139 137 102 93 103 160 179 181 215 223 198 223 177 196 134 126 85 60 55 55 44 117 151 136 139 140 138 140 138 136 135 122 47 3 7 74 34 28 33 15 20 20 23 82 116 135 133 141 141 136 107 75 86 100 116 138 190 206 212 213 200 212 183 198 165 159 139 103 95 130 142 146 150 149 143 139 142 142 137 95 19 4 20 58 23 28 44 12 13 15 13 58 103 127 132 134 138 137 120 84 72 86 99 104 121 131 141 144 146 144 151 137 129 116 104 119 141 145 146 149 152 150 141 145 148 141 128 56 5 7 25 49 25 9 68 51 33 26 20 32 88 117 130 131 133 132 126 108 87 74 86 98 125 136 129 164 144 100 89 83 76 84 112 137 145 146 151 144 147 143 142 151 147 135 95 18 11 10 35 93 42 16 94 84 63 46 27 19 60 105 124 127 131 126 124 119 112 108 94 86 105 125 122 136 119 88 84 88 95 118 138 152 152 148 142 143 146 145 146 146 138 114 46 6 17 10 28 76 23 21 100 90 80 62 34 15 30 88 117 120 126 126 124 118 116 125 124 116 102 94 98 93 102 107 115 115 122 133 143 147 149 142 138 145 139 143 147 137 121 74 8 13 17 25 64 56 28 9 64 65 65 50 31 25 13 53 100 117 125 127 129 125 122 124 127 135 133 130 130 131 130 126 126 124 134 141 144 140 143 139 139 136 136 141 135 116 87 38 7 12 14 19 73 77 26 8 52 19 23 38 35 18 12 20 71 108 123 131 134 127 135 136 143 144 144 142 138 135 130 129 127 128 136 138 139 139 139 138 133 136 136 131 114 84 59 21 9 12 14 10 23 25 9 14 103 55 29 23 21 17 12 9 33 83 113 124 131 133 140 139 145 156 164 160 155 150 142 136 133 133 138 138 136 138 137 132 132 130 125 109 78 61 56 12 6 11 14 12 9 7 13 12 98 44 21 21 16 16 15 13 13 50 98 119 126 136 141 148 155 161 166 164 159 156 149 142 140 140 140 138 136 135 134 129 130 123 105 74 55 66 53 6 10 10 12 11 8 12 12 9\",\n          \"95 91 40 4 7 7 7 7 6 6 7 18 23 7 4 5 9 18 33 41 47 54 58 61 63 66 68 74 80 84 83 80 77 66 56 44 32 23 21 15 11 6 7 6 5 5 6 15 99 73 14 5 7 6 5 5 5 6 7 22 20 4 6 7 12 26 41 46 51 57 61 62 65 68 72 81 88 91 91 91 93 90 80 67 47 27 21 16 11 9 8 6 5 4 5 21 91 39 7 7 6 6 4 5 5 6 8 25 21 5 8 9 17 33 44 48 53 56 61 65 67 73 78 85 93 97 100 98 99 101 99 91 68 40 24 17 14 11 8 6 5 4 5 20 67 27 7 7 6 5 4 5 6 6 11 28 24 6 9 11 23 39 47 52 54 58 62 66 68 73 80 91 98 103 106 105 103 104 100 95 77 53 31 22 12 8 7 6 5 5 6 18 50 25 3 7 6 6 6 4 4 6 11 28 29 7 11 16 30 44 49 53 55 59 63 67 71 76 84 94 102 108 109 108 108 108 105 100 77 57 38 22 15 7 8 7 4 4 8 19 51 19 4 5 6 6 6 6 5 6 11 28 33 11 13 17 34 47 49 53 56 58 64 68 73 79 86 94 105 109 108 107 110 112 110 99 82 61 42 26 14 7 7 7 6 4 7 15 55 12 6 7 7 6 6 6 4 6 7 25 34 12 14 19 38 48 50 52 54 65 65 71 76 80 87 96 104 109 108 107 110 111 111 104 86 69 46 30 17 9 7 7 6 5 8 11 44 8 7 7 6 5 5 5 4 3 5 20 34 13 13 18 38 47 50 53 55 69 68 72 77 82 88 94 102 103 99 106 109 109 109 108 100 87 59 35 20 13 9 7 6 6 7 12 30 9 6 6 5 5 5 4 5 4 4 17 34 14 13 18 36 45 48 55 62 65 67 72 78 82 89 94 97 97 96 104 107 107 106 111 108 103 91 63 34 17 10 9 9 9 7 9 28 5 4 5 4 4 5 4 5 4 4 14 33 14 13 19 36 46 49 55 59 64 68 72 76 79 84 92 96 96 99 103 106 104 107 113 111 111 112 102 68 33 11 7 8 10 8 8 16 5 4 5 4 4 5 6 6 5 4 13 32 13 13 20 37 47 49 53 58 64 67 69 75 78 81 87 94 96 100 103 102 102 104 109 111 109 111 113 99 68 24 6 4 5 6 7 7 5 5 4 4 5 5 6 6 5 5 12 31 13 14 23 37 47 50 53 56 61 65 69 73 77 80 86 90 94 96 97 94 98 106 112 110 108 112 112 109 95 55 12 6 7 7 7 5 5 4 4 5 5 7 7 6 8 7 14 25 12 15 26 39 46 47 52 55 60 63 64 68 74 79 82 86 85 80 70 61 57 68 87 97 102 107 109 110 104 89 34 6 7 7 6 5 5 4 4 4 5 6 6 5 10 7 15 23 13 16 28 39 44 46 48 54 58 60 61 63 63 58 54 46 38 32 36 54 74 89 102 102 102 108 111 113 108 103 61 12 6 6 6 5 5 5 5 5 4 5 6 6 10 5 16 18 12 17 27 36 41 43 46 52 57 58 57 54 41 29 25 19 23 45 63 79 89 103 107 111 114 116 120 119 112 108 82 22 6 7 7 5 6 6 5 5 4 7 8 8 10 7 20 9 6 9 15 26 36 40 44 52 57 56 58 54 41 40 39 40 47 46 51 61 68 78 93 98 102 111 122 122 118 113 98 36 5 7 6 7 7 4 4 5 4 11 10 13 11 12 21 7 6 7 8 11 23 33 40 50 60 66 69 74 63 47 38 28 22 19 20 22 44 66 65 72 88 106 120 125 123 115 108 56 6 8 8 6 6 5 4 5 4 11 10 18 11 20 17 9 9 9 11 12 15 21 31 43 62 78 87 79 45 32 22 13 10 9 4 8 25 38 40 52 78 99 118 128 127 119 112 76 12 4 5 7 6 5 5 5 5 13 13 18 15 22 9 5 5 6 5 6 9 12 22 36 62 89 105 84 38 21 20 20 30 23 5 7 55 74 50 76 101 103 117 130 125 118 111 91 24 2 6 6 5 5 4 4 10 14 18 17 22 18 6 5 4 5 5 6 6 7 14 31 60 94 116 101 60 31 25 21 34 40 25 17 48 81 91 112 116 111 121 131 124 115 110 96 38 12 11 5 5 5 4 4 12 15 20 20 27 11 7 8 6 5 5 13 12 12 17 30 53 90 119 105 78 56 40 27 27 29 35 45 62 89 101 109 111 116 126 129 122 113 108 97 49 45 23 5 5 6 4 8 16 19 19 26 25 8 6 7 7 9 10 18 16 21 21 28 51 82 108 108 94 71 47 36 31 33 42 56 73 84 97 106 117 120 124 127 120 115 107 101 64 57 49 5 5 6 6 13 17 19 23 29 19 11 7 7 6 10 14 14 13 17 20 28 48 74 101 111 102 93 78 58 50 46 50 60 69 79 93 106 114 119 122 122 117 113 107 100 85 81 67 5 5 6 13 19 19 23 27 15 17 14 9 8 7 9 11 12 16 23 22 29 49 71 99 116 113 110 102 84 78 72 68 69 71 81 98 109 115 118 119 117 110 106 107 100 93 96 83 7 7 12 19 20 23 30 14 7 17 13 10 9 10 12 16 21 25 26 26 29 49 71 98 114 118 120 110 95 88 83 82 78 82 86 99 109 114 115 111 110 107 105 105 99 95 97 92 9 12 17 18 21 29 19 5 5 14 13 12 13 13 16 23 27 29 28 25 30 50 72 94 108 115 122 114 98 88 87 85 87 87 93 98 106 108 109 108 106 106 106 105 100 97 92 46 7 11 14 19 25 17 8 5 4 9 13 12 12 14 19 27 30 30 29 26 33 52 68 91 106 116 125 114 92 86 89 91 92 90 92 97 101 102 103 104 105 106 106 105 99 98 63 0 9 12 22 23 17 10 6 4 4 6 13 12 14 17 23 30 31 29 27 27 38 54 62 89 109 118 115 111 74 74 81 89 94 93 93 96 96 99 100 101 104 105 105 104 98 97 38 0 13 19 27 25 14 6 4 4 3 4 10 13 14 18 24 29 29 27 26 29 45 56 66 95 124 127 124 123 80 60 70 79 90 93 95 97 98 99 102 102 105 107 108 105 101 92 19 1 9 12 14 12 5 4 4 4 4 3 5 11 14 19 25 28 29 25 23 27 44 56 67 96 104 104 117 123 82 60 55 67 84 92 94 96 98 103 105 105 105 108 108 105 102 81 9 4 7 6 5 5 5 5 4 4 4 3 3 7 13 18 23 28 30 26 24 24 28 45 61 95 83 67 85 99 88 81 67 59 74 88 95 95 99 102 105 106 109 109 108 104 100 64 2 5 7 6 6 6 4 5 4 4 4 4 3 5 12 16 21 27 30 28 27 24 21 29 42 65 82 104 115 105 94 93 95 82 71 80 93 96 101 105 107 107 110 111 110 105 97 43 0 5 7 6 5 5 4 5 4 5 4 4 4 4 8 14 21 26 28 27 27 25 23 25 38 33 39 78 94 93 93 95 98 97 90 80 92 99 104 109 110 111 110 109 108 104 89 21 0 4 7 7 6 7 5 4 4 3 4 4 5 4 7 13 21 24 25 25 25 24 24 29 46 48 40 64 86 87 90 93 93 93 96 91 86 99 105 113 115 115 111 109 104 98 73 9 4 6 6 7 6 6 5 4 5 4 5 5 5 5 6 11 21 24 24 24 24 23 23 27 44 49 44 64 87 94 102 108 107 100 95 90 81 96 105 112 115 111 108 106 101 97 54 6 4 6 7 7 5 5 5 4 5 5 5 5 5 4 8 17 19 23 24 23 24 24 23 21 24 32 44 52 54 61 66 67 73 65 63 80 75 92 105 111 109 108 107 102 99 83 47 10 3 4 6 7 7 7 5 5 5 6 5 4 5 4 10 19 16 24 25 22 21 18 15 14 14 16 22 28 31 31 33 37 35 46 83 90 77 81 100 106 105 106 105 98 90 68 46 11 4 4 6 7 7 7 5 5 5 4 4 4 5 7 5 12 19 24 25 24 21 14 12 12 13 16 20 27 38 48 62 74 75 98 107 101 90 84 96 101 102 103 101 91 83 65 48 14 3 4 6 7 7 7 5 4 5 5 4 5 6 4 17 28 15 19 24 23 23 21 18 18 18 26 40 43 50 66 70 80 95 104 103 99 98 92 97 98 99 100 94 85 81 65 56 25 2 5 7 7 7 7 5 5 5 5 4 6 6 9 14 10 3 8 23 23 23 23 21 20 19 21 30 37 45 58 71 83 92 96 97 98 100 96 100 99 100 96 85 83 80 66 61 35 2 5 6 7 7 7 5 5 5 6 5 6 7 14 8 6 5 3 13 24 24 23 23 23 23 30 31 36 38 44 61 75 86 93 97 104 103 100 100 97 93 83 81 83 82 73 64 46 6 5 6 6 6 6 4 3 4 5 5 6 7 6 7 7 6 4 3 15 24 22 23 24 25 31 34 38 45 53 64 77 87 92 98 104 103 99 98 89 79 78 82 85 84 78 69 61 17 4 6 6 6 6 5 5 5 5 7 6 6 7 6 6 7 5 0 24 28 20 23 24 26 31 39 45 54 66 75 85 92 94 101 101 101 98 86 70 70 75 79 86 86 82 78 69 38 11 7 6 6 6 6 4 13 21 13 12 10 6 6 7 7 6 21 32 12 17 24 24 26 30 37 45 53 65 75 84 93 99 103 101 98 82 67 67 70 70 77 83 87 87 84 76 57 40 5 6 5 5 6 4 52 34 16 25 20 16 5 11 7 8 17 6 4 5 19 24 25 28 37 44 49 61 74 83 91 97 98 98 80 66 69 70 71 69 73 82 87 90 87 83 68 63 6 6 5 7 11 14 39 14 22 36 34 19 14 17 6 6 4 5 5 4 8 21 24 26 33 43 44 51 66 80 88 90 90 74 67 74 74 72 73 70 73 80 87 89 89 87 76 74 7 6 14 23 37 46 16 13 35 33 16 9 12 7 5 5 6 5 4 6 8 13 21 23 26 34 38 43 51 67 74 67 54 59 71 76 75 71 69 69 71 78 86 90 89 85 81 82 8 8 20 42 51 35 21 27 28 18 7 6 5 6 5 4 5 4 5 8 12 13 16 20 23 26 29 30 36 39 35 31 42 59 69 74 73 70 67 65 69 76 83 90 89 85 84 82\",\n          \"38 36 34 30 18 17 16 17 17 14 17 15 29 55 64 67 75 80 88 93 100 99 96 88 89 89 84 87 89 88 91 92 93 94 88 83 77 62 36 19 17 24 16 14 16 17 17 14 34 33 32 21 14 15 14 13 11 12 13 14 34 60 69 67 76 84 87 95 95 94 93 93 90 90 89 88 90 90 91 93 92 93 92 83 82 73 50 22 17 19 20 12 13 13 15 12 34 33 27 13 12 13 13 12 10 12 13 16 42 63 69 68 75 84 85 83 83 78 83 88 90 90 91 90 90 89 89 86 85 84 90 85 81 76 62 31 14 16 18 10 11 9 12 11 33 31 20 11 11 13 13 12 11 13 12 21 51 67 60 51 56 59 50 45 42 45 59 71 84 88 84 88 88 83 81 76 69 60 65 71 75 73 65 43 15 12 13 7 12 10 10 10 32 27 13 11 12 12 12 10 13 13 13 31 48 46 31 32 37 27 18 24 25 28 35 50 76 87 84 83 85 82 74 60 44 34 29 35 44 49 52 45 22 10 10 7 9 11 8 8 31 23 10 11 11 11 10 9 12 13 17 31 33 25 22 27 22 16 15 18 23 28 31 46 64 80 88 86 86 76 64 45 27 17 15 14 13 16 21 26 23 11 9 8 9 10 7 10 28 16 10 12 10 10 10 13 11 14 20 26 32 29 30 29 32 40 47 47 48 43 45 46 54 68 87 88 85 68 48 32 23 21 18 16 16 17 15 14 9 8 9 9 7 10 7 9 24 11 9 11 9 9 9 11 12 17 23 37 49 40 36 44 55 55 55 60 60 53 48 49 53 60 84 88 81 55 33 31 31 37 46 45 41 40 42 31 17 8 10 10 4 10 8 8 19 8 10 9 8 9 9 10 13 21 34 50 58 48 41 43 40 24 23 36 42 49 50 48 49 63 85 89 75 44 29 27 35 44 46 49 50 49 44 43 37 17 11 10 5 8 7 7 13 9 10 9 8 9 9 11 13 28 44 57 61 47 30 20 15 16 18 14 32 38 55 49 45 65 79 80 68 39 28 38 42 33 20 22 23 33 38 36 35 25 12 8 7 5 7 6 10 10 10 9 8 9 9 8 15 40 52 59 55 43 26 38 37 18 15 24 68 56 51 51 46 66 77 75 64 37 33 38 36 39 15 19 10 13 18 20 27 31 15 8 8 4 7 6 9 10 8 8 9 9 8 7 30 54 59 61 60 59 46 55 65 51 41 46 55 48 51 50 48 63 76 76 64 39 33 34 56 65 22 14 12 32 29 13 25 33 19 10 8 4 6 6 7 9 9 7 8 10 7 12 43 53 63 68 70 71 58 53 64 72 68 62 55 43 41 45 48 57 65 65 59 39 35 42 42 51 39 25 30 52 45 25 31 33 20 12 9 7 6 6 8 9 9 6 14 59 51 39 66 59 58 74 75 73 69 60 59 60 62 63 56 51 43 44 48 57 61 64 56 38 31 38 41 49 49 55 61 60 43 39 45 36 24 15 10 8 7 6 9 8 8 3 37 78 69 66 83 71 52 68 76 71 65 67 70 66 63 64 62 60 50 48 48 51 62 66 52 38 35 39 44 53 57 59 60 54 51 56 56 44 30 19 10 8 7 6 8 9 7 1 39 75 62 67 74 78 61 63 78 67 71 78 75 72 67 66 66 58 52 47 48 50 65 67 48 38 37 43 49 55 65 68 66 63 65 67 62 52 32 22 11 7 6 5 8 9 7 2 31 76 69 58 81 89 64 62 72 77 73 77 84 80 77 73 65 59 49 49 47 53 70 68 51 37 37 41 54 61 66 70 71 70 68 65 65 60 38 22 10 5 6 5 9 9 8 4 26 81 72 61 94 93 63 56 71 84 82 62 80 85 82 77 68 60 55 48 47 60 74 73 60 40 38 43 55 68 74 71 72 71 68 66 68 61 43 23 10 3 6 5 9 9 8 2 30 87 72 64 99 94 64 55 69 78 86 68 67 82 80 78 73 67 52 44 52 68 77 78 64 44 37 46 55 68 73 74 76 73 70 68 66 61 43 23 10 2 5 4 9 9 7 2 26 83 72 61 95 99 64 54 69 79 89 72 59 81 80 79 83 70 47 49 61 83 86 86 74 45 35 46 61 66 67 79 81 75 72 72 65 59 46 25 8 1 4 3 10 9 6 3 18 77 76 62 98 103 60 48 68 84 94 75 58 81 83 86 88 63 52 56 55 79 98 87 73 43 34 47 66 67 69 76 79 74 69 68 60 55 44 23 4 0 3 3 10 9 5 4 16 82 81 71 104 104 63 39 64 86 95 77 57 81 87 89 82 62 60 47 37 65 82 74 53 34 44 48 68 73 76 78 78 77 73 65 59 56 42 20 2 1 2 3 10 9 7 4 19 86 85 77 107 103 72 32 63 96 102 76 52 83 91 92 79 62 55 27 11 51 68 62 23 19 51 48 72 78 78 79 77 76 72 66 59 50 36 13 0 2 2 2 10 9 7 3 24 88 81 77 107 104 70 30 77 102 99 76 56 86 94 89 83 69 48 52 45 46 58 45 16 33 42 50 78 83 78 80 77 70 65 64 55 44 31 7 1 2 2 2 10 9 6 4 24 86 74 70 102 101 67 39 86 100 101 78 59 88 87 85 85 77 59 53 57 53 41 35 43 46 43 61 78 87 82 81 77 69 64 60 52 45 27 3 1 2 2 2 9 8 7 5 19 82 71 63 101 102 65 49 80 99 102 77 55 87 77 84 83 78 75 64 63 59 53 61 50 49 60 66 76 84 84 79 75 68 61 56 49 42 20 2 3 2 2 4 9 8 6 6 16 77 67 71 96 104 66 56 78 97 105 75 52 76 78 82 81 80 75 69 68 73 75 75 55 58 68 70 73 78 83 79 70 66 58 52 47 32 15 3 4 4 3 5 10 7 5 4 24 70 56 83 103 100 67 56 79 107 104 72 42 63 72 74 79 76 69 67 71 76 74 76 60 55 60 68 69 68 77 81 67 62 57 46 37 25 13 3 3 4 5 6 11 7 6 0 36 71 54 86 107 101 64 59 89 110 107 82 41 61 72 74 75 74 73 71 79 73 72 78 65 60 58 63 64 61 63 75 70 59 54 40 32 22 9 4 3 4 6 7 11 7 6 1 35 76 57 81 105 104 68 59 90 110 109 89 43 61 74 77 78 77 75 71 72 74 75 76 72 68 66 64 60 59 58 69 74 59 50 36 28 22 7 3 4 4 6 8 10 8 6 2 22 76 60 75 106 108 70 61 95 110 110 88 38 50 65 61 53 46 46 50 47 47 51 53 55 56 64 67 60 59 60 62 69 54 43 33 29 23 4 1 5 7 7 9 9 7 5 3 15 70 65 75 108 108 73 63 94 106 109 83 38 41 40 34 32 34 37 39 39 35 33 36 34 32 35 45 52 52 60 59 64 52 38 31 28 20 4 2 6 8 9 10 8 5 4 3 15 70 65 71 108 110 76 61 90 101 104 78 38 48 57 57 54 53 57 58 56 56 57 54 46 38 33 26 26 37 58 64 64 51 38 30 27 18 2 2 6 10 9 11 7 5 4 3 17 67 70 64 99 108 80 59 86 102 99 89 61 42 59 70 70 72 68 63 61 60 60 59 55 49 50 44 43 55 71 68 63 48 36 29 27 14 1 3 7 11 9 10 7 5 3 3 13 62 75 59 93 106 81 58 83 97 103 100 78 56 50 61 63 63 61 57 48 48 49 53 55 57 54 51 60 69 75 69 62 48 32 28 27 9 0 3 8 10 8 10 8 5 3 3 6 57 77 59 84 96 74 58 78 94 107 103 87 78 56 44 56 56 54 52 52 50 49 50 49 52 52 56 60 66 68 63 59 46 29 29 23 5 0 4 8 8 8 9 8 5 4 4 3 50 75 60 81 88 75 64 79 95 105 102 99 93 72 42 47 58 66 73 78 76 71 64 57 61 60 59 60 58 60 55 52 38 29 31 16 0 2 6 9 8 8 9 8 6 5 5 2 43 72 57 79 88 74 69 85 98 106 106 104 96 83 81 67 62 68 75 81 81 77 74 70 66 61 57 59 54 52 50 47 33 31 28 8 0 2 7 9 9 9 8 8 7 5 6 2 40 66 56 78 84 68 67 82 97 99 103 101 99 99 97 89 76 63 70 80 79 76 74 68 73 69 64 58 57 51 47 38 30 30 18 4 1 4 8 10 10 11 6 8 7 5 6 2 37 62 62 79 82 65 64 71 87 92 98 96 99 102 104 95 88 78 69 77 84 84 76 65 66 76 66 63 60 51 43 31 29 24 7 3 1 7 9 11 10 12 6 7 6 5 6 2 39 61 65 84 84 70 61 58 70 86 88 92 99 101 103 103 97 89 80 69 70 79 74 67 58 59 64 65 59 52 39 28 25 12 6 4 3 9 9 10 13 11 8 7 6 5 6 3 41 61 66 88 88 75 67 57 55 72 81 89 96 102 103 104 105 100 91 81 68 60 59 65 55 52 59 60 53 45 31 24 13 7 7 4 5 10 9 10 14 10 8 8 7 5 4 4 47 62 54 83 84 78 74 72 58 60 75 83 91 97 100 103 109 106 99 89 83 74 59 48 47 45 52 55 43 31 22 11 10 10 8 4 6 9 9 10 13 8 8 8 7 5 4 5 53 73 43 56 73 75 71 71 67 62 67 76 84 91 98 102 105 107 103 98 90 86 81 56 37 40 49 45 30 18 12 10 13 10 8 4 7 9 9 11 14 7 9 8 7 5 4 5 49 77 55 35 47 59 63 71 65 68 68 69 81 86 92 98 102 104 104 103 97 90 89 81 48 35 44 30 18 11 7 13 14 11 7 5 7 12 11 10 10 7 10 7 7 6 4 2 32 70 68 50 40 40 44 56 61 64 72 66 71 83 87 89 95 98 100 102 102 99 96 90 76 42 25 20 13 11 11 14 13 9 6 4 8 12 11 9 7 7 9 8 8 7 6 8 13 42 55 54 48 47 48 44 55 57 57 63 64 74 81 81 97 97 97 104 104 99 97 93 88 69 26 15 13 12 14 14 14 10 3 4 9 10 10 8 19 15 8 12 13 12 13 15 16 26 36 47 42 38 42 37 36 51 57 60 61 65 72 79 95 97 97 99 105 110 105 107 94 82 58 25 10 14 11 20 14 7 11 11 18 16 9 5 20 19 15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_submission_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aJUm1RHd64km",
        "outputId": "98e4b9b4-2ff1-48f7-f6c4-012b43eac43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   3\n",
              "0  4\n",
              "1  0\n",
              "2  4\n",
              "3  3\n",
              "4  3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-650b3b04-b571-4bde-b823-5e91d10a80ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-650b3b04-b571-4bde-b823-5e91d10a80ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-650b3b04-b571-4bde-b823-5e91d10a80ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-650b3b04-b571-4bde-b823-5e91d10a80ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-75444642-49a0-4a42-a035-3579ee5e16ae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75444642-49a0-4a42-a035-3579ee5e16ae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-75444642-49a0-4a42-a035-3579ee5e16ae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "example_submission_df",
              "summary": "{\n  \"name\": \"example_submission_df\",\n  \"rows\": 3588,\n  \"fields\": [\n    {\n      \"column\": \"3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4,\n          0,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_data_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rEZeESqp7AD7",
        "outputId": "ef085c6e-45f6-4da6-e3f8-cfe917d21fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   emotion     Usage                                             pixels\n",
              "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9eac1f48-34e1-44d7-a4dc-489134228d81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>Usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Training</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Training</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Training</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9eac1f48-34e1-44d7-a4dc-489134228d81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9eac1f48-34e1-44d7-a4dc-489134228d81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9eac1f48-34e1-44d7-a4dc-489134228d81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-37c9417e-db87-4233-92c6-61595bf71ffe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37c9417e-db87-4233-92c6-61595bf71ffe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-37c9417e-db87-4233-92c6-61595bf71ffe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "face_data_df",
              "summary": "{\n  \"name\": \"face_data_df\",\n  \"rows\": 35887,\n  \"fields\": [\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Usage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Training\",\n          \"PublicTest\",\n          \"PrivateTest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" pixels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34034,\n        \"samples\": [\n          \"34 40 24 31 27 18 26 21 28 86 131 143 146 143 135 126 141 153 136 132 138 134 131 135 133 134 124 118 109 99 92 87 79 65 59 37 25 30 21 15 10 28 79 79 81 81 80 77 42 29 31 33 21 22 27 19 36 100 129 134 145 151 143 149 166 163 147 154 154 148 146 140 135 134 127 124 114 105 100 93 81 67 57 47 33 25 20 22 15 17 69 76 81 81 81 78 35 32 32 30 25 29 23 24 49 118 118 138 156 157 158 178 182 162 169 168 156 154 147 143 139 134 132 126 119 111 103 100 85 69 59 43 42 26 18 17 15 16 58 80 79 80 81 81 31 34 30 24 30 27 22 25 79 122 131 160 167 175 186 189 181 177 177 168 162 162 152 144 138 137 133 127 123 115 104 99 89 74 59 44 37 34 18 16 14 8 45 80 78 79 80 79 39 30 23 32 37 26 27 36 91 136 174 178 183 187 187 186 187 184 177 172 168 165 157 147 143 142 135 130 123 114 101 98 90 76 62 48 32 33 21 15 15 9 38 73 78 77 77 76 37 28 33 40 30 27 33 49 123 184 187 188 186 188 190 189 188 184 179 173 173 169 160 154 147 145 138 131 127 110 100 97 89 75 61 51 35 28 19 14 15 9 33 65 74 76 76 76 46 40 46 37 27 31 43 70 178 189 188 185 188 190 191 187 188 182 177 176 172 168 161 156 151 144 140 133 129 113 101 95 86 76 63 53 41 24 17 12 16 11 27 65 77 78 75 73 35 38 38 30 34 42 51 125 198 185 190 189 189 191 190 188 185 182 177 177 174 170 165 158 150 143 139 135 126 118 108 97 82 72 64 56 42 28 16 13 15 11 23 68 79 75 72 70 35 40 33 36 39 50 83 167 190 186 190 190 187 187 188 186 186 180 174 178 177 173 168 159 152 146 142 136 131 122 108 99 85 74 63 53 45 39 22 12 14 10 26 66 74 73 71 70 47 40 40 42 45 62 128 186 184 184 183 184 183 178 178 176 180 176 172 173 177 175 169 161 152 145 143 140 133 127 114 102 91 75 64 55 48 42 30 12 14 11 24 63 69 73 70 68 38 45 36 50 43 89 163 188 195 198 196 183 176 177 180 181 179 174 170 168 174 175 170 165 155 145 144 146 139 131 122 109 95 75 64 54 49 46 36 15 13 11 24 64 64 68 66 67 45 43 40 59 48 134 186 170 147 128 117 102 103 96 88 112 148 158 149 152 161 171 169 167 158 147 147 148 145 135 131 124 105 83 68 58 54 49 42 15 12 14 17 63 62 63 64 67 54 30 65 53 78 182 179 158 152 162 177 193 195 166 118 61 48 60 84 101 138 163 170 166 161 152 148 149 147 144 143 134 112 82 58 47 43 46 51 14 12 14 13 58 64 62 65 68 47 32 77 46 136 191 185 199 207 208 206 201 198 203 200 183 141 97 95 105 136 158 172 172 171 160 152 148 153 147 135 106 73 32 15 16 23 25 36 15 11 14 17 50 65 63 67 69 28 42 61 65 181 191 193 193 192 191 193 198 195 158 135 122 140 166 164 158 167 179 181 184 173 162 153 151 153 141 110 92 56 53 76 77 66 49 40 16 11 16 22 47 66 64 68 68 27 49 39 120 195 193 197 193 190 184 179 150 77 72 73 83 63 84 141 168 179 194 199 197 185 169 147 143 145 150 155 137 133 141 129 121 89 55 60 18 11 17 22 43 66 66 68 67 37 32 45 172 194 194 201 196 187 187 134 122 137 132 78 120 132 92 121 160 157 194 208 211 197 173 133 95 86 94 65 63 73 44 46 47 51 56 58 17 12 17 24 36 67 66 68 65 44 12 77 193 186 195 196 196 193 184 162 163 161 120 125 144 169 93 76 165 168 197 205 214 199 164 97 46 42 33 63 47 83 81 60 42 52 49 59 16 12 17 24 29 65 65 66 65 46 8 105 194 188 193 188 185 183 183 189 185 165 139 122 128 107 90 100 150 186 191 196 207 193 147 68 41 34 48 56 60 65 103 60 29 52 57 59 14 13 19 25 24 58 64 64 64 43 7 124 192 185 190 186 180 179 181 188 201 199 183 166 139 133 127 132 134 168 179 191 196 181 135 63 38 43 53 71 66 72 67 54 52 46 61 58 10 15 20 24 22 55 64 62 61 37 8 133 191 185 192 187 181 177 178 180 188 189 182 170 154 138 132 131 147 161 170 187 190 174 130 70 39 37 45 62 83 89 78 74 60 63 68 53 8 16 20 22 22 56 65 60 60 32 8 137 188 189 195 193 191 184 176 174 173 169 169 163 154 151 150 152 162 166 170 183 186 176 136 77 47 46 44 50 62 78 80 68 65 67 74 50 8 16 20 23 20 51 62 58 57 33 6 137 192 190 199 201 200 192 180 171 166 163 161 158 155 155 157 161 170 171 173 182 186 176 146 100 76 63 56 55 61 67 70 72 77 75 77 42 7 17 19 25 18 43 65 59 56 34 10 137 192 190 200 203 199 194 188 179 171 166 160 160 158 160 164 166 172 172 174 179 183 175 143 103 90 87 81 71 64 70 76 78 81 78 75 32 8 20 18 23 18 30 67 64 58 30 11 132 192 189 193 196 195 195 194 188 178 170 164 163 162 163 167 172 179 181 176 176 179 168 144 109 91 88 90 92 85 73 73 77 77 73 71 21 11 19 18 23 18 20 57 58 54 32 6 132 190 184 190 193 194 195 193 188 183 177 169 166 164 166 171 179 192 189 177 175 175 164 145 119 97 88 88 92 95 93 78 70 70 68 63 12 14 19 16 24 20 15 45 48 42 29 16 131 185 185 191 191 194 195 194 192 186 180 174 169 170 168 172 181 189 179 176 174 173 163 146 125 100 82 86 89 92 94 97 81 60 64 48 7 16 20 15 22 24 14 33 46 40 48 47 133 184 185 191 191 192 196 196 194 192 185 177 172 168 167 169 179 174 161 169 178 179 166 152 130 97 71 82 90 99 104 104 97 72 60 30 9 17 20 17 22 25 15 24 40 42 65 48 131 183 184 190 191 193 195 197 195 192 187 179 173 166 164 165 179 178 176 181 193 193 172 163 137 92 74 86 106 118 115 109 97 87 70 13 13 17 20 18 20 27 18 19 30 36 62 44 122 182 183 190 192 194 197 197 196 195 192 184 173 164 162 166 185 200 193 190 193 197 180 167 119 88 92 114 135 133 120 109 93 85 75 24 12 18 20 15 19 24 21 19 23 27 62 44 111 184 179 188 191 193 195 200 201 201 197 186 173 166 167 176 177 176 167 179 195 187 182 145 108 122 89 121 140 137 124 108 90 83 61 50 22 17 18 15 18 19 21 21 19 22 65 47 103 180 181 188 192 193 199 205 205 200 196 187 175 171 176 180 179 171 176 187 195 187 142 59 41 55 65 100 129 134 126 106 87 78 50 53 47 18 16 15 18 17 23 27 16 34 68 47 96 173 183 188 193 200 204 205 204 202 195 187 180 180 180 182 184 182 181 180 179 163 132 69 53 58 60 71 104 126 123 100 84 68 47 53 57 37 12 14 19 16 22 33 17 36 70 48 82 166 181 192 197 203 204 204 203 200 195 192 188 185 186 188 187 184 182 176 151 156 164 95 58 55 58 63 77 104 116 92 83 55 50 54 54 54 20 13 18 17 18 33 24 21 64 56 60 154 181 196 198 201 203 203 203 201 198 196 190 184 185 186 187 184 178 172 138 136 155 90 56 54 54 62 74 80 95 87 74 48 53 54 54 56 40 13 17 18 17 26 29 18 66 56 50 129 184 191 197 197 200 201 203 202 198 190 187 187 192 196 191 187 180 172 156 136 130 102 64 52 60 76 77 83 69 69 63 49 54 54 54 53 53 26 14 21 20 19 34 20 68 56 48 69 186 188 195 196 197 201 201 197 191 188 171 129 137 146 141 140 134 140 132 117 102 112 113 64 92 112 84 82 60 41 33 56 53 55 54 53 54 42 15 20 20 16 31 24 66 56 37 15 147 198 192 198 198 198 194 192 189 185 173 170 145 130 137 133 116 102 94 100 72 61 58 65 104 112 95 72 54 20 11 45 56 54 54 52 52 53 24 16 19 16 29 29 68 50 28 9 59 201 189 198 200 194 193 190 189 186 184 189 196 184 175 170 153 128 109 119 90 68 65 78 105 118 92 61 33 9 14 21 53 54 54 52 51 56 38 16 24 18 25 32 67 32 25 25 6 128 210 191 194 193 194 191 190 188 187 184 187 191 190 178 161 146 130 121 102 83 81 87 95 110 91 40 9 17 17 14 32 56 53 52 52 54 52 20 20 22 21 33 58 21 29 22 23 17 161 204 188 194 194 194 194 192 190 187 186 184 181 173 160 159 155 154 136 109 87 86 88 93 79 29 15 19 15 17 15 47 53 52 53 53 57 30 18 24 23 32 45 18 29 23 27 19 34 170 201 188 192 194 194 193 191 190 191 185 178 163 158 152 156 154 133 110 88 82 87 77 50 56 28 14 17 16 12 30 54 52 53 53 57 41 18 23 24 32 33 20 28 26 24 27 47 60 154 204 187 192 195 194 199 202 194 186 176 165 163 144 132 126 116 96 79 83 75 49 55 60 48 12 21 18 16 17 48 52 53 54 58 49 19 24 22 30 27 17 33 29 24 32 65 64 58 132 199 193 189 200 206 204 199 190 176 169 161 146 124 102 76 67 83 73 50 56 58 57 57 28 20 20 15 12 36 54 52 54 57 56 22 22 21 24 27 16 35 28 21 46 66 65 73 64 109 180 198 198 200 202 204 197 186 174 164 154 133 101 60 49 58 55 53 63 57 59 56 47 20 17 16 12 25 53 53 55 57 58 27 19 23 18 30 18 28 33 20 52 66 68 73 83 81 100 152 197 203 201 197 194 185 170 162 157 139 104 67 44 19 47 55 60 53 58 56 57 27 13 18 14 18 48 52 56 56 59 33 18 22 21 32 16 26 33 24 55 65 66 70 75 90 92 86 123 159 181 187 186 178 168 167 160 139 97 53 42 27 25 50 59 54 57 57 60 36 12 21 14 15 45 54 55 55 61 39 19 22 21 37 16 23 29 30 64 69 66 68 72 83 79 82 93 100 111 121 122 122 129 136 131 113 55 55 51 32 18 38 60 57 59 60 62 44 15 20 15 13 41 55 56 57 59 42 18 24 18\",\n          \"30 31 31 31 31 31 32 32 32 34 41 46 35 60 70 51 58 110 101 77 60 53 51 42 43 47 38 26 19 14 14 14 17 21 20 20 17 20 21 26 35 35 34 33 31 29 27 27 30 31 31 31 31 31 32 32 33 38 46 36 49 63 55 60 113 103 74 72 63 53 44 43 41 32 24 19 16 13 11 12 13 15 19 21 20 20 19 20 29 36 35 33 31 29 28 28 30 31 31 31 31 32 33 34 35 40 40 34 39 50 56 116 97 65 59 50 43 35 33 40 30 16 14 15 16 15 11 9 10 12 16 17 20 19 18 16 17 31 36 34 32 30 28 28 30 31 31 31 32 32 35 36 42 37 29 24 39 53 96 108 66 76 76 64 53 52 45 35 23 13 8 4 2 3 9 11 12 11 14 17 18 20 19 21 15 17 37 35 33 30 28 28 30 31 31 31 31 32 36 38 42 23 17 16 30 65 137 141 155 158 148 145 145 149 144 129 118 112 100 83 68 41 7 3 10 13 13 14 17 18 21 24 24 15 24 37 33 30 29 28 30 31 31 31 31 32 33 41 30 13 7 9 53 134 181 192 201 199 192 192 192 194 194 185 178 173 165 155 141 125 89 39 8 6 12 12 15 17 17 21 28 19 10 33 35 31 29 28 30 31 31 31 31 33 35 42 24 14 10 69 154 193 204 206 207 206 202 200 200 198 194 189 185 172 159 153 144 132 127 118 75 26 10 11 11 16 17 15 24 29 9 20 36 32 29 28 30 30 31 32 32 33 43 36 25 10 43 154 195 196 201 207 208 208 206 202 202 200 196 192 187 175 164 155 149 141 134 131 120 85 37 14 14 14 18 18 15 25 17 6 30 33 29 28 30 30 32 32 32 33 43 34 19 8 112 188 191 198 203 207 207 206 204 202 201 200 196 193 188 180 170 163 153 143 139 138 126 104 73 28 16 15 14 16 19 18 19 1 17 32 29 28 30 30 31 32 31 33 46 27 8 37 167 189 193 199 206 208 206 203 203 202 200 199 197 193 188 180 172 166 156 148 143 139 127 113 89 43 18 14 16 14 21 24 10 0 6 28 31 28 30 31 31 31 32 36 44 20 6 78 184 189 194 200 206 207 205 203 202 201 202 201 197 191 187 182 175 168 159 149 143 138 125 114 104 72 35 14 15 17 16 23 9 0 1 20 32 28 30 31 31 32 32 39 40 12 7 97 185 189 196 201 205 208 207 204 204 204 204 204 199 193 190 185 178 171 163 153 144 136 126 114 104 97 76 36 14 16 17 21 19 19 8 14 32 28 30 30 31 32 32 40 43 10 11 97 185 189 195 200 204 207 210 210 207 206 206 205 201 194 188 185 182 176 171 159 147 142 131 113 104 98 89 69 29 16 20 21 23 60 43 8 30 29 30 30 31 31 31 41 49 8 11 94 184 190 195 199 203 208 212 213 208 207 207 207 204 195 187 183 174 156 137 115 105 111 116 117 108 100 93 80 47 16 20 22 24 33 43 18 26 31 30 31 31 32 30 49 62 8 8 85 180 189 194 198 205 208 210 211 207 206 206 204 199 193 167 133 95 73 73 79 85 83 79 85 100 102 96 87 60 21 18 20 22 26 48 38 25 33 30 31 31 32 31 49 71 9 6 76 174 188 192 200 208 213 213 209 205 203 203 196 190 179 127 81 72 85 104 118 113 106 98 85 90 102 99 93 77 29 16 18 19 24 37 43 28 37 30 30 30 32 29 48 79 11 6 59 165 185 195 205 203 192 177 186 198 195 196 188 177 153 105 81 72 64 68 59 48 46 57 83 93 98 100 97 89 46 19 17 19 18 32 45 22 39 30 31 31 32 30 52 77 19 7 42 154 187 172 143 123 97 95 123 168 186 190 183 163 119 85 72 53 79 89 25 45 68 30 55 97 110 109 101 94 72 32 22 17 17 23 43 13 34 31 31 31 32 32 57 80 29 1 18 148 163 105 109 116 115 108 112 134 169 193 192 161 102 81 77 66 162 126 55 77 86 70 89 123 134 122 106 97 90 62 29 22 14 17 29 10 24 30 31 31 33 33 56 77 31 0 7 126 127 142 169 136 91 70 67 80 140 193 198 162 106 95 115 122 150 149 131 117 112 121 144 153 143 127 109 98 91 83 45 27 13 20 20 7 16 30 30 31 32 33 53 71 33 8 16 97 147 165 113 58 86 76 38 82 129 190 196 164 118 115 133 154 149 144 143 139 145 160 165 157 139 123 111 99 90 88 60 29 14 23 24 10 14 30 30 30 31 33 53 63 35 9 19 94 170 139 44 111 163 66 75 132 165 194 194 166 130 121 131 146 157 160 164 172 180 181 171 153 135 121 110 99 89 85 66 31 19 26 31 13 13 30 30 30 31 32 59 64 35 9 19 88 173 151 87 122 151 144 155 149 183 199 196 167 136 125 126 145 162 174 182 183 182 178 165 149 133 120 108 100 87 84 66 30 30 29 40 19 12 30 30 30 32 34 61 65 40 15 13 81 168 180 169 163 163 153 146 177 190 196 200 165 134 120 120 142 163 167 177 183 182 176 162 145 130 116 106 100 87 83 63 34 38 29 38 25 10 30 30 30 32 35 63 66 41 21 6 62 168 190 190 186 179 177 194 204 187 192 203 175 145 120 114 127 146 162 171 175 177 172 160 142 127 111 102 99 88 83 59 36 36 28 32 23 7 30 30 31 32 37 68 70 38 25 11 46 164 184 194 201 203 205 207 199 186 191 204 189 159 123 117 130 118 132 154 162 167 164 152 136 119 106 98 97 91 84 50 11 28 23 27 19 9 30 30 31 33 38 67 64 41 26 17 30 147 177 188 198 204 208 205 197 184 189 206 196 165 131 123 134 101 88 123 144 154 153 141 126 113 101 96 95 93 80 61 20 22 20 24 18 9 30 30 31 31 38 67 63 45 26 14 7 105 174 179 190 198 203 199 182 175 188 196 185 145 102 89 77 72 77 98 117 134 138 130 119 103 94 93 92 93 77 65 43 21 20 22 15 5 30 30 30 32 39 66 60 46 28 12 1 56 163 174 185 189 193 185 151 154 160 148 149 105 75 65 68 81 87 95 103 106 117 119 108 95 89 90 89 93 79 38 27 30 19 19 15 8 30 30 30 30 39 71 58 47 27 10 5 17 136 171 178 183 180 164 129 154 149 108 110 86 71 79 87 92 100 101 103 109 111 116 112 97 91 86 89 95 74 39 11 30 22 16 12 9 30 30 30 30 45 71 56 43 27 7 6 2 77 164 167 171 167 144 124 168 185 171 155 140 119 117 113 114 117 108 98 88 103 130 127 106 90 84 90 93 66 40 13 26 23 16 13 8 30 31 31 30 47 68 54 41 24 6 5 2 61 153 158 160 153 127 118 171 182 185 194 192 180 159 110 84 74 72 53 41 105 135 133 102 84 86 90 88 57 41 12 26 25 15 12 7 30 31 30 29 47 66 51 42 23 5 7 7 85 118 153 148 143 110 124 184 190 182 155 132 120 88 86 106 115 98 71 101 127 125 130 98 84 88 88 80 46 42 10 21 26 15 12 8 31 30 30 30 49 63 50 40 23 3 7 10 76 64 138 146 144 111 142 156 122 95 123 143 156 167 205 172 138 108 108 120 118 123 128 97 87 87 84 65 44 44 7 25 29 13 14 10 31 31 31 32 51 58 49 38 21 3 11 10 56 46 107 151 147 132 148 145 78 78 188 207 215 185 159 124 130 115 103 108 116 122 120 94 88 84 79 49 47 36 5 24 33 13 15 10 31 32 31 35 48 50 46 30 16 5 13 18 27 33 63 144 142 143 153 186 181 152 153 162 169 150 147 145 106 87 95 109 114 116 106 91 87 79 66 38 53 31 6 22 32 18 16 10 31 31 31 35 48 48 39 23 14 5 15 22 24 35 25 117 141 139 151 176 180 155 151 176 168 152 137 105 78 88 101 108 112 111 97 85 79 73 45 43 53 23 6 25 32 22 19 10 31 31 31 35 44 41 40 22 15 7 21 28 24 37 24 55 141 137 151 166 174 167 143 128 124 111 87 79 89 101 104 114 116 100 87 76 71 59 31 55 43 14 6 26 36 22 21 14 31 31 29 37 43 40 38 18 13 11 25 30 27 34 33 7 82 145 145 161 165 167 157 136 116 107 97 110 118 118 124 127 111 92 78 69 65 35 41 53 29 8 8 27 35 26 19 15 31 31 30 38 43 39 38 19 15 14 29 31 29 29 32 14 7 105 144 149 162 163 158 152 149 149 147 150 147 140 137 126 99 80 67 62 41 26 53 43 21 9 11 28 36 29 18 13 30 31 31 37 39 34 43 19 13 18 37 31 27 25 32 16 2 22 115 143 153 165 165 163 168 172 170 164 156 143 130 107 81 64 57 45 22 46 49 34 17 8 12 30 42 32 19 15 30 30 31 38 36 28 44 22 14 18 42 35 26 21 29 12 6 5 38 109 136 152 165 170 174 172 162 153 144 132 107 80 59 51 42 23 38 51 42 29 16 6 15 29 39 36 22 18 30 30 29 39 33 30 46 26 16 18 45 40 26 16 26 12 6 6 12 38 92 125 146 162 164 157 139 126 125 102 73 56 46 36 25 39 49 46 39 27 14 10 21 28 40 36 21 20 30 30 31 39 34 29 48 33 16 19 45 37 28 14 26 10 11 4 6 26 34 65 102 118 129 126 110 104 91 65 47 37 31 29 43 49 49 47 39 28 12 13 21 26 44 36 23 22 30 30 29 36 33 32 47 31 19 17 44 37 31 15 24 10 8 5 14 34 30 31 61 111 92 77 67 60 48 37 27 27 39 53 51 47 49 50 36 27 11 15 20 27 46 35 24 26 30 30 29 34 36 36 43 30 18 17 44 39 30 14 26 15 11 2 27 36 47 33 23 95 138 102 80 59 44 35 39 56 62 57 49 47 57 51 36 25 11 19 24 27 43 33 26 28 29 29 32 37 35 36 42 24 15 17 47 40 30 15 25 14 14 9 24 26 48 38 17 49 129 131 110 98 86 83 82 77 69 60 56 60 62 49 37 17 16 22 26 28 46 33 24 29 29 28 31 39 35 41 40 22 17 16 44 41 30 18 25 12 10 16 22 27 43 42 23 41 110 140 127 116 111 105 96 88 78 70 71 67 61 52 34 19 22 21 25 33 48 34 25 30\",\n          \"172 170 169 140 56 27 43 49 40 22 29 30 30 46 55 88 115 129 135 134 144 143 138 137 148 165 160 145 148 141 136 139 123 97 89 73 47 28 20 26 16 13 13 14 14 12 10 10 172 170 166 109 43 34 36 35 18 22 14 21 42 65 98 120 132 138 137 144 153 161 162 157 164 167 163 160 152 150 145 149 137 118 107 85 62 51 31 31 21 11 12 9 11 14 12 11 170 168 154 74 36 37 34 23 20 13 21 37 59 100 123 134 139 143 149 154 160 170 175 174 175 170 169 168 160 159 154 152 146 133 117 107 90 66 53 37 24 22 15 10 9 10 12 12 167 167 123 52 43 42 29 20 10 17 32 58 87 112 129 138 147 158 161 167 174 180 183 182 182 180 170 168 168 169 166 159 146 140 127 115 105 101 88 64 49 37 17 12 11 11 12 12 165 157 87 44 56 35 20 14 11 24 51 76 98 118 134 144 159 165 163 175 182 184 184 186 189 183 173 175 175 175 170 163 156 141 135 118 112 110 96 91 76 56 48 26 16 11 9 10 168 129 55 51 63 27 14 8 14 34 60 89 107 128 142 155 165 169 173 183 193 193 192 192 194 190 187 180 179 177 174 172 159 139 133 113 117 119 115 103 83 66 55 41 23 10 11 11 159 90 45 54 52 22 10 10 23 55 75 95 122 137 148 157 169 175 185 187 189 187 192 197 194 195 192 192 190 185 178 173 163 146 134 133 131 121 109 110 100 85 66 38 31 23 12 12 121 66 49 57 43 18 10 11 43 79 94 107 122 133 147 162 173 175 181 188 185 189 196 197 196 196 192 190 188 186 182 175 167 153 143 143 130 129 127 119 111 96 82 58 34 27 13 13 91 47 49 53 36 12 12 17 56 82 102 114 125 139 149 163 175 174 177 186 187 191 195 194 194 193 188 185 185 185 182 175 167 153 148 148 144 137 138 129 126 115 89 62 42 26 19 15 81 48 52 38 29 13 10 16 54 93 112 114 127 135 147 164 178 177 175 186 185 189 194 195 198 195 190 190 184 183 182 175 169 161 150 145 147 142 135 134 135 124 100 65 45 32 24 12 62 51 46 31 19 14 10 13 68 109 114 120 128 140 147 161 172 173 177 186 183 189 190 195 196 194 193 192 183 178 185 174 165 163 159 153 145 142 138 134 129 118 106 84 41 33 26 11 52 49 42 27 14 12 9 12 74 107 117 126 144 158 161 170 178 172 181 195 191 188 192 197 189 191 196 197 180 178 184 173 168 163 163 163 152 148 142 134 125 112 100 87 70 55 33 17 51 49 36 20 13 10 9 16 74 113 125 130 150 164 181 189 184 178 191 196 193 191 194 199 195 191 198 207 189 173 186 176 176 174 174 168 159 154 143 132 122 115 100 92 84 73 35 18 58 50 36 16 14 10 9 16 86 114 110 112 104 121 131 137 144 168 182 177 173 188 192 197 190 176 180 187 185 179 174 165 157 148 143 153 145 131 129 122 121 116 108 99 95 88 53 27 53 43 33 22 12 13 7 25 93 107 128 132 136 113 92 84 91 115 151 144 143 177 191 194 184 160 146 148 141 129 118 106 104 112 128 144 141 138 127 119 119 119 115 106 97 96 78 37 47 35 33 23 10 14 5 38 106 122 138 154 168 166 159 129 105 102 120 128 139 170 186 184 175 154 137 127 103 90 88 95 127 159 168 164 161 153 140 132 128 114 116 113 104 101 98 53 41 35 31 13 11 13 5 59 117 118 130 147 145 155 161 157 140 127 124 129 131 158 189 191 172 150 135 132 120 122 141 163 180 177 163 162 159 148 134 128 125 128 125 123 112 99 98 133 39 36 22 14 12 12 10 79 119 114 103 101 124 150 147 138 126 128 134 131 133 149 189 195 174 159 147 141 128 126 125 135 154 155 144 140 140 130 127 118 111 119 128 129 116 87 153 196 37 35 24 14 11 10 18 97 121 111 92 111 118 131 142 138 124 130 131 140 140 152 184 191 178 164 147 133 112 109 83 101 139 151 150 153 152 130 112 99 102 113 132 129 139 101 183 187 40 31 22 14 11 6 32 116 134 111 66 29 9 39 157 166 155 132 120 137 148 158 181 189 179 161 148 122 113 99 85 38 51 68 149 131 113 103 94 87 92 105 136 178 181 102 179 195 40 27 19 14 11 4 46 133 145 104 58 62 62 60 206 216 180 146 137 142 157 166 182 188 179 163 154 141 112 105 138 88 67 107 170 120 74 51 65 97 129 119 177 198 159 80 160 195 41 26 23 12 12 4 59 139 145 137 145 107 94 113 133 143 152 154 163 167 164 167 181 183 177 168 167 163 145 131 130 144 146 137 130 144 148 136 137 147 153 127 191 200 170 77 134 200 53 27 12 10 12 4 71 145 149 163 155 138 125 127 134 144 148 165 184 174 167 166 180 179 167 161 170 171 177 167 141 133 140 137 146 152 157 160 162 167 161 129 196 200 169 94 124 208 57 21 11 10 12 5 92 147 157 164 164 159 156 153 155 160 183 200 183 169 159 167 176 174 162 150 157 170 178 192 195 185 172 165 166 171 173 182 178 178 165 145 211 201 185 106 97 202 59 16 10 11 10 7 100 151 163 169 172 170 167 169 177 188 200 195 177 161 160 167 171 173 166 153 145 169 173 191 201 203 202 198 198 197 193 192 185 182 160 167 216 199 187 117 71 188 47 12 11 11 11 9 101 152 169 180 181 184 187 193 198 197 203 199 172 158 174 179 183 185 174 152 131 149 181 196 206 207 209 206 204 203 199 190 183 182 148 171 212 187 169 103 72 177 39 12 11 11 11 7 101 153 166 177 182 190 195 203 208 213 212 194 156 162 190 216 209 200 186 154 142 134 146 206 216 219 216 211 208 203 200 196 190 175 154 208 203 171 136 98 129 194 32 13 11 11 11 3 89 156 159 173 182 193 201 207 220 219 203 170 170 176 187 205 200 186 188 187 188 176 134 148 213 220 218 215 207 202 200 201 193 159 188 209 192 167 120 94 152 210 32 12 11 11 12 2 67 154 158 172 185 196 206 214 216 209 179 178 187 167 160 171 176 165 161 180 184 191 167 111 182 215 216 216 210 206 202 200 174 172 219 205 187 166 127 93 189 215 28 12 11 10 13 4 45 144 157 171 184 194 203 209 206 193 176 167 118 83 85 143 153 129 110 77 80 150 172 112 176 216 216 216 206 204 201 183 161 202 220 209 193 165 108 105 197 203 27 12 10 9 12 3 25 134 155 171 184 191 202 206 202 189 190 162 146 162 174 193 162 177 191 181 182 165 138 135 196 211 213 211 203 198 178 162 201 217 214 207 187 164 116 160 199 188 29 11 10 12 6 24 45 111 157 166 179 192 196 200 197 193 186 171 156 147 172 206 186 191 184 167 157 151 156 181 192 203 212 204 196 178 157 200 218 213 208 195 178 150 117 192 197 176 26 9 11 9 14 76 11 77 155 159 175 184 191 193 192 188 180 171 162 155 167 185 172 178 172 158 165 176 184 188 191 193 199 192 180 152 197 224 221 211 204 183 170 152 123 170 179 160 26 11 15 2 60 41 0 46 140 155 166 179 184 184 179 180 166 160 149 147 156 159 158 164 161 162 166 175 180 185 187 185 187 172 144 168 210 222 217 208 199 174 168 162 150 155 160 147 26 11 14 13 71 11 9 20 123 151 160 169 175 167 164 164 141 144 146 157 172 168 185 180 164 162 158 158 165 169 168 165 159 140 179 218 218 216 212 205 182 164 166 161 156 151 145 144 21 12 11 26 69 3 13 7 94 142 155 166 166 156 157 139 138 140 147 173 184 198 209 197 194 186 175 167 160 153 135 121 106 170 223 220 222 216 210 199 169 161 168 162 155 142 135 147 20 10 14 29 67 6 13 3 71 136 144 159 160 151 138 119 130 133 140 144 157 172 162 162 158 147 143 142 142 129 106 58 138 220 221 223 217 213 213 195 169 166 177 162 145 124 139 140 18 10 14 16 52 15 10 5 47 128 132 147 156 153 131 106 99 124 132 137 131 130 135 132 132 134 132 141 125 93 56 103 216 219 221 221 216 210 203 189 171 169 169 155 134 131 152 139 17 11 16 19 33 33 7 10 25 109 128 138 154 158 130 95 119 148 164 168 174 173 179 186 184 195 184 155 137 104 102 207 219 223 224 218 215 203 192 181 172 166 159 151 139 152 148 125 20 11 14 24 18 31 17 12 10 73 134 129 144 159 142 118 119 130 153 172 191 195 198 212 192 184 155 133 117 74 173 222 221 221 222 216 209 197 187 174 168 161 157 149 145 149 133 100 20 13 11 20 25 15 16 10 16 41 119 129 133 147 147 139 126 119 125 147 160 166 159 166 152 133 119 106 77 138 226 218 225 224 218 215 200 188 180 171 165 159 152 146 147 136 113 110 16 15 14 13 20 19 14 10 19 13 69 131 122 136 140 144 129 120 122 133 135 135 133 128 122 118 114 107 127 213 222 226 227 223 216 209 196 184 176 166 160 155 145 138 139 123 116 129 24 15 16 13 14 19 11 13 15 10 23 109 120 127 136 139 130 126 133 136 130 127 133 131 135 142 136 119 182 227 226 228 223 218 214 207 190 178 171 164 153 151 142 135 127 119 127 130 47 24 22 20 15 18 17 13 15 20 6 50 121 118 129 135 132 131 133 136 138 139 150 154 163 164 144 164 220 222 229 226 220 214 210 203 187 175 166 154 151 149 134 126 123 128 127 115 64 50 33 24 21 22 25 25 26 18 13 5 81 125 121 137 135 136 139 146 150 159 166 171 174 171 157 204 226 224 224 219 213 214 208 194 183 173 161 149 148 141 129 121 120 126 115 91 66 65 57 42 28 25 28 29 30 22 13 7 14 98 124 134 137 135 141 153 160 162 165 168 179 178 174 212 224 227 225 218 216 210 205 195 180 169 159 147 141 131 121 115 118 117 103 57 68 69 67 59 43 33 29 29 33 32 21 10 5 26 100 122 134 138 141 150 158 163 161 157 173 176 183 214 218 219 220 215 211 207 200 190 176 165 153 142 132 123 115 113 114 108 82 15 73 67 67 65 57 47 37 34 39 38 34 13 9 19 57 98 116 133 137 141 150 158 158 154 163 162 180 217 213 213 212 215 212 204 192 178 168 158 147 135 121 113 113 112 108 105 53 11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert pixel strings to numpy arrays\n",
        "def process_pixels(pixels_str):\n",
        "    return np.array(pixels_str.split(), dtype='float32')\n",
        "\n",
        "# For training\n",
        "train_df['pixels'] = train_df['pixels'].apply(process_pixels)\n",
        "x_train = np.stack(train_df['pixels'].values)\n",
        "y_train = train_df['emotion'].values\n",
        "\n",
        "# For testing\n",
        "test_df['pixels'] = test_df['pixels'].apply(process_pixels)\n",
        "x_test = np.stack(test_df['pixels'].values)"
      ],
      "metadata": {
        "id": "h-WUp8ke7CUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize and reshape\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(-1, 48, 48, 1)\n",
        "x_test = x_test.reshape(-1, 48, 48, 1)"
      ],
      "metadata": {
        "id": "XjGtwXkZ73iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape, x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9W-vNv48Erq",
        "outputId": "64390934-b668-4657-e0aa-130a89d622d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7178, 48, 48, 1), (28709, 48, 48, 1), (28709,))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_dict = {\n",
        "    0: \"Angry\",\n",
        "    1: \"Disgust\",\n",
        "    2: \"Fear\",\n",
        "    3: \"Happy\",\n",
        "    4: \"Sad\",\n",
        "    5: \"Surprise\",\n",
        "    6: \"Neutral\"\n",
        "}\n",
        "\n",
        "plt.imshow(x_train[idx].squeeze(), cmap='gray')\n",
        "plt.title(f'Emotion: {emotion_dict[y_train[idx]]}')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lbrdXzh38m5M",
        "outputId": "6f18c1ed-047a-43f5-935c-0c6bb43f9a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-eb92c603ab1d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Emotion: {emotion_dict[y_train[idx]]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.2 Wandb"
      ],
      "metadata": {
        "id": "8S8DLQl89_6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "aMF2ggrz-Zj3",
        "outputId": "c60541ac-a997-4bc9-92f4-c1b8c414c696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnkhar21\u001b[0m (\u001b[33mnkhar21-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WANDB_API_KEY  = 'f8a227b42dc881e037b25911fa86b8a491fc0581'"
      ],
      "metadata": {
        "id": "4hqoyesU-fNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"ML_4\", entity=\"nkhar21-student\", name=\"test_run\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "gLqj01Mk_Kjy",
        "outputId": "f9af2a19-ab12-4cbb-8cb1-3af4d013977e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250530_155943-x3hspr1z</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nkhar21-student/ML_4/runs/x3hspr1z' target=\"_blank\">test_run</a></strong> to <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nkhar21-student/ML_4/runs/x3hspr1z' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/x3hspr1z</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nkhar21-student/ML_4/runs/x3hspr1z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b0b38260c10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log({\"Hello\": 1, \"Test_log\": 1})"
      ],
      "metadata": {
        "id": "nyXHcLcvADsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "uWLHlpUE_PkE",
        "outputId": "bf8f4522-520b-49d6-bad7-c3561752d5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Hello</td><td>▁</td></tr><tr><td>Test_log</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Hello</td><td>1</td></tr><tr><td>Test_log</td><td>1</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">test_run</strong> at: <a href='https://wandb.ai/nkhar21-student/ML_4/runs/x3hspr1z' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/x3hspr1z</a><br> View project at: <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250530_155943-x3hspr1z/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 48 * 48\n",
        "output_dim = 7\n",
        "hidden_layer_size = 48 * 4\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and validation sets (e.g. 80% train, 20% val)\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, x_val.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDbqzy95R9o",
        "outputId": "775f8938-a51f-44b4-8a47-b53d8163f0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((22967, 48, 48, 1), (7178, 48, 48, 1), (22967,), (5742, 48, 48, 1), (5742,))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Basic FC Training"
      ],
      "metadata": {
        "id": "zkau9BjGr3sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import wandb\n",
        "\n",
        "# === 1. WANDB INIT ===\n",
        "wandb.init(project=\"ML_4\", entity=\"nkhar21-student\", name=\"First_Basic_FC\")\n",
        "\n",
        "# === 2. CONFIG ===\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === 3. CONVERT TO TENSORS ===\n",
        "def prepare_tensor(x, y):\n",
        "    x_tensor = torch.tensor(x, dtype=torch.float32).permute(0, 3, 1, 2)  # (N, 1, 48, 48)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "    return x_tensor, y_tensor\n",
        "\n",
        "x_train_tensor, y_train_tensor = prepare_tensor(x_train, y_train)\n",
        "x_val_tensor, y_val_tensor = prepare_tensor(x_val, y_val)\n",
        "x_test_tensor = torch.tensor(x_test, dtype=torch.float32).permute(0, 3, 1, 2)  # just to save for prediction later\n",
        "\n",
        "# === 4. DATALOADERS ===\n",
        "train_loader = DataLoader(TensorDataset(x_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(x_val_tensor, y_val_tensor), batch_size=batch_size)\n",
        "\n",
        "# === 5. MODEL ===\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(input_dim, hidden_layer_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_layer_size, output_dim),\n",
        ")\n",
        "model.to(device)\n",
        "wandb.watch(model)\n",
        "\n",
        "# === 6. LOSS + OPTIMIZER ===\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# === 7. TRAINING LOOP ===\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss, train_correct, train_total = 0, 0, 0\n",
        "\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = loss_fn(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_correct += (preds == batch_y).sum().item()\n",
        "        train_total += batch_y.size(0)\n",
        "\n",
        "    train_acc = train_correct / train_total\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # === VALIDATION ===\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in val_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            loss = loss_fn(outputs, batch_y)\n",
        "            val_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += (preds == batch_y).sum().item()\n",
        "            val_total += batch_y.size(0)\n",
        "\n",
        "    val_acc = val_correct / val_total\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"  Val   Loss: {avg_val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
        "    print(f\"  Test  Samples: {x_test_tensor.shape[0]} (held out for prediction)\")\n",
        "\n",
        "    # === LOG TO WANDB ===\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": avg_train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"val_loss\": avg_val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "        \"test_samples\": x_test_tensor.shape[0],\n",
        "    })\n",
        "\n",
        "# === 8. SAVE MODEL ===\n",
        "torch.save(model.state_dict(), \"basic_model.pth\")\n",
        "wandb.save(\"basic_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "-4a-wGN5r2C8",
        "outputId": "920b6815-51fc-4aa3-9b14-7dc0706c572d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">First_Basic_FC</strong> at: <a href='https://wandb.ai/nkhar21-student/ML_4/runs/ahn2wpsw' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/ahn2wpsw</a><br> View project at: <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250530_160945-ahn2wpsw/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250530_161151-4rfcbad1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nkhar21-student/ML_4/runs/4rfcbad1' target=\"_blank\">First_Basic_FC</a></strong> to <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nkhar21-student/ML_4/runs/4rfcbad1' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/4rfcbad1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  Train Loss: 1.8092 | Train Acc: 0.2543\n",
            "  Val   Loss: 1.7821 | Val   Acc: 0.2682\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 2/10\n",
            "  Train Loss: 1.7699 | Train Acc: 0.2787\n",
            "  Val   Loss: 1.7528 | Val   Acc: 0.2891\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 3/10\n",
            "  Train Loss: 1.7387 | Train Acc: 0.3072\n",
            "  Val   Loss: 1.7315 | Val   Acc: 0.3370\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 4/10\n",
            "  Train Loss: 1.7112 | Train Acc: 0.3298\n",
            "  Val   Loss: 1.6909 | Val   Acc: 0.3521\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 5/10\n",
            "  Train Loss: 1.6928 | Train Acc: 0.3404\n",
            "  Val   Loss: 1.7056 | Val   Acc: 0.3326\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 6/10\n",
            "  Train Loss: 1.6793 | Train Acc: 0.3443\n",
            "  Val   Loss: 1.6628 | Val   Acc: 0.3565\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 7/10\n",
            "  Train Loss: 1.6675 | Train Acc: 0.3482\n",
            "  Val   Loss: 1.6651 | Val   Acc: 0.3617\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 8/10\n",
            "  Train Loss: 1.6554 | Train Acc: 0.3563\n",
            "  Val   Loss: 1.7066 | Val   Acc: 0.3201\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 9/10\n",
            "  Train Loss: 1.6493 | Train Acc: 0.3581\n",
            "  Val   Loss: 1.6487 | Val   Acc: 0.3553\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 10/10\n",
            "  Train Loss: 1.6400 | Train Acc: 0.3637\n",
            "  Val   Loss: 1.6519 | Val   Acc: 0.3624\n",
            "  Test  Samples: 7178 (held out for prediction)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20250530_161151-4rfcbad1/files/basic_model.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jsl17uuVHpqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Training FC 2"
      ],
      "metadata": {
        "id": "z64TUB3PHryg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import wandb\n",
        "\n",
        "# === 1. WANDB INIT ===\n",
        "wandb.init(project=\"ML_4\", entity=\"nkhar21-student\", name=\"Decomposed_Eval_Model\")\n",
        "\n",
        "# === 2. CONFIG ===\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === 3. TEST TENSOR (for prediction later) ===\n",
        "x_test_tensor = torch.tensor(x_test, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "\n",
        "# === 4. MODEL ===\n",
        "input_dim = 48 * 48\n",
        "hidden1 = 48*4\n",
        "hidden2 = 48\n",
        "hidden3 = 28  # 7*4\n",
        "output_dim = 7\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(input_dim, hidden1),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden1, hidden2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden2, hidden3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden3, output_dim),\n",
        ")\n",
        "model.to(device)\n",
        "wandb.watch(model)\n",
        "\n",
        "# === 5. LOSS + OPTIMIZER ===\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# === 6. EVALUATION FUNCTION ===\n",
        "def evaluate_model(x, y, model, loss_fn, device, batch_size=64, train_mode=False):\n",
        "    x_tensor = torch.tensor(x, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "    loader = DataLoader(TensorDataset(x_tensor, y_tensor), batch_size=batch_size, shuffle=train_mode)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if train_mode:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    with torch.set_grad_enabled(train_mode):\n",
        "        for batch_x, batch_y in loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            loss = loss_fn(outputs, batch_y)\n",
        "\n",
        "            if train_mode:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# === 7. TRAINING LOOP ===\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = evaluate_model(x_train, y_train, model, loss_fn, device, batch_size, train_mode=True)\n",
        "    val_loss, val_acc = evaluate_model(x_val, y_val, model, loss_fn, device, batch_size, train_mode=False)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "    })\n",
        "\n",
        "# === 8. SAVE MODEL ===\n",
        "torch.save(model.state_dict(), \"decomposed_eval_model.pth\")\n",
        "wandb.save(\"decomposed_eval_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bJ7nJWFe9Ovd",
        "outputId": "d714f0a1-12d8-47c1-8a0c-a0366524dd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test_samples</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▇▆██▅▇█</td></tr><tr><td>val_loss</td><td>█▆▅▃▄▂▂▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_samples</td><td>7178</td></tr><tr><td>train_accuracy</td><td>0.3637</td></tr><tr><td>train_loss</td><td>1.63997</td></tr><tr><td>val_accuracy</td><td>0.36242</td></tr><tr><td>val_loss</td><td>1.65192</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">First_Basic_FC</strong> at: <a href='https://wandb.ai/nkhar21-student/ML_4/runs/4rfcbad1' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/4rfcbad1</a><br> View project at: <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250530_161151-4rfcbad1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250530_170113-vql4x0yr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nkhar21-student/ML_4/runs/vql4x0yr' target=\"_blank\">Decomposed_Eval_Model</a></strong> to <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nkhar21-student/ML_4/runs/vql4x0yr' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/vql4x0yr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  Train Loss: 1.8498 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8131 | Val   Acc: 0.2513\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 2/10\n",
            "  Train Loss: 1.8111 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8053 | Val   Acc: 0.2513\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 3/10\n",
            "  Train Loss: 1.8042 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.7984 | Val   Acc: 0.2513\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 4/10\n",
            "  Train Loss: 1.7966 | Train Acc: 0.2511\n",
            "  Val   Loss: 1.7904 | Val   Acc: 0.2517\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 5/10\n",
            "  Train Loss: 1.7879 | Train Acc: 0.2528\n",
            "  Val   Loss: 1.7812 | Val   Acc: 0.2564\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 6/10\n",
            "  Train Loss: 1.7764 | Train Acc: 0.2585\n",
            "  Val   Loss: 1.7671 | Val   Acc: 0.2593\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 7/10\n",
            "  Train Loss: 1.7609 | Train Acc: 0.2695\n",
            "  Val   Loss: 1.7505 | Val   Acc: 0.2928\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 8/10\n",
            "  Train Loss: 1.7395 | Train Acc: 0.2947\n",
            "  Val   Loss: 1.7279 | Val   Acc: 0.2935\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 9/10\n",
            "  Train Loss: 1.7185 | Train Acc: 0.3182\n",
            "  Val   Loss: 1.7217 | Val   Acc: 0.3281\n",
            "  Test  Samples: 7178 (held out for prediction)\n",
            "Epoch 10/10\n",
            "  Train Loss: 1.7021 | Train Acc: 0.3276\n",
            "  Val   Loss: 1.6892 | Val   Acc: 0.3433\n",
            "  Test  Samples: 7178 (held out for prediction)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20250530_170113-vql4x0yr/files/decomposed_eval_model.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3 Training FC_3"
      ],
      "metadata": {
        "id": "GEyRyJT3K6lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import wandb\n",
        "\n",
        "# === 1. WANDB INIT ===\n",
        "wandb.init(project=\"ML_4\", entity=\"nkhar21-student\", name=\"FC_1\")\n",
        "\n",
        "# === 2. CONFIG ===\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === 3. MODEL ===\n",
        "input_dim = 48 * 48\n",
        "hidden1 = 256\n",
        "hidden2 = 64\n",
        "hidden3 = 28  # 7*4\n",
        "output_dim = 7\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(input_dim, hidden1),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden1, hidden2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden2, hidden3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden3, output_dim),\n",
        ")\n",
        "model.to(device)\n",
        "wandb.watch(model)\n",
        "\n",
        "# === 4. LOSS + OPTIMIZER ===\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# === 5. TRAINING LOOP ===\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = evaluate_model(x_train, y_train, model, loss_fn, device, batch_size, train_mode=True)\n",
        "    val_loss, val_acc = evaluate_model(x_val, y_val, model, loss_fn, device, batch_size, train_mode=False)\n",
        "\n",
        "    # Overfitting metrics\n",
        "    loss_gap = train_loss - val_loss\n",
        "    acc_gap = train_acc - val_acc\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
        "    print(f\"  Loss Gap:   {loss_gap:.4f} | Acc  Gap:  {acc_gap:.4f}\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "        \"loss_gap\": loss_gap,\n",
        "        \"acc_gap\": acc_gap,\n",
        "    })\n",
        "\n",
        "# === 6. SAVE MODEL ===\n",
        "torch.save(model.state_dict(), \"decomposed_eval_model.pth\")\n",
        "wandb.save(\"decomposed_eval_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RS7EyBooK-La",
        "outputId": "3ce488c7-2d51-493a-d96c-b98a1552a841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test_samples</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▂▃▅▇█</td></tr><tr><td>train_loss</td><td>█▆▆▅▅▅▄▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▂▄▄▇█</td></tr><tr><td>val_loss</td><td>██▇▇▆▅▄▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_samples</td><td>7178</td></tr><tr><td>train_accuracy</td><td>0.32756</td></tr><tr><td>train_loss</td><td>1.70214</td></tr><tr><td>val_accuracy</td><td>0.34326</td></tr><tr><td>val_loss</td><td>1.68922</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Decomposed_Eval_Model</strong> at: <a href='https://wandb.ai/nkhar21-student/ML_4/runs/vql4x0yr' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/vql4x0yr</a><br> View project at: <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250530_170113-vql4x0yr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250530_171029-uxv5ud0o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nkhar21-student/ML_4/runs/uxv5ud0o' target=\"_blank\">FC_1</a></strong> to <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nkhar21-student/ML_4/runs/uxv5ud0o' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/uxv5ud0o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "  Train Loss: 1.8756 | Train Acc: 0.2264\n",
            "  Val   Loss: 1.8181 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0574 | Acc  Gap:  -0.0249\n",
            "Epoch 2/20\n",
            "  Train Loss: 1.8124 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8083 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0041 | Acc  Gap:  0.0000\n",
            "Epoch 3/20\n",
            "  Train Loss: 1.8057 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8007 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0050 | Acc  Gap:  0.0000\n",
            "Epoch 4/20\n",
            "  Train Loss: 1.7981 | Train Acc: 0.2514\n",
            "  Val   Loss: 1.7945 | Val   Acc: 0.2499\n",
            "  Loss Gap:   0.0036 | Acc  Gap:  0.0014\n",
            "Epoch 5/20\n",
            "  Train Loss: 1.7900 | Train Acc: 0.2528\n",
            "  Val   Loss: 1.7878 | Val   Acc: 0.2517\n",
            "  Loss Gap:   0.0022 | Acc  Gap:  0.0011\n",
            "Epoch 6/20\n",
            "  Train Loss: 1.7795 | Train Acc: 0.2587\n",
            "  Val   Loss: 1.7722 | Val   Acc: 0.2597\n",
            "  Loss Gap:   0.0072 | Acc  Gap:  -0.0009\n",
            "Epoch 7/20\n",
            "  Train Loss: 1.7631 | Train Acc: 0.2710\n",
            "  Val   Loss: 1.7599 | Val   Acc: 0.2614\n",
            "  Loss Gap:   0.0033 | Acc  Gap:  0.0096\n",
            "Epoch 8/20\n",
            "  Train Loss: 1.7418 | Train Acc: 0.2926\n",
            "  Val   Loss: 1.7329 | Val   Acc: 0.3100\n",
            "  Loss Gap:   0.0088 | Acc  Gap:  -0.0174\n",
            "Epoch 9/20\n",
            "  Train Loss: 1.7253 | Train Acc: 0.3057\n",
            "  Val   Loss: 1.7141 | Val   Acc: 0.3069\n",
            "  Loss Gap:   0.0112 | Acc  Gap:  -0.0012\n",
            "Epoch 10/20\n",
            "  Train Loss: 1.7099 | Train Acc: 0.3170\n",
            "  Val   Loss: 1.7209 | Val   Acc: 0.3015\n",
            "  Loss Gap:   -0.0109 | Acc  Gap:  0.0155\n",
            "Epoch 11/20\n",
            "  Train Loss: 1.7005 | Train Acc: 0.3262\n",
            "  Val   Loss: 1.6967 | Val   Acc: 0.3215\n",
            "  Loss Gap:   0.0037 | Acc  Gap:  0.0047\n",
            "Epoch 12/20\n",
            "  Train Loss: 1.6909 | Train Acc: 0.3331\n",
            "  Val   Loss: 1.7277 | Val   Acc: 0.2999\n",
            "  Loss Gap:   -0.0367 | Acc  Gap:  0.0332\n",
            "Epoch 13/20\n",
            "  Train Loss: 1.6826 | Train Acc: 0.3345\n",
            "  Val   Loss: 1.6824 | Val   Acc: 0.3429\n",
            "  Loss Gap:   0.0002 | Acc  Gap:  -0.0084\n",
            "Epoch 14/20\n",
            "  Train Loss: 1.6762 | Train Acc: 0.3372\n",
            "  Val   Loss: 1.6737 | Val   Acc: 0.3342\n",
            "  Loss Gap:   0.0025 | Acc  Gap:  0.0030\n",
            "Epoch 15/20\n",
            "  Train Loss: 1.6697 | Train Acc: 0.3415\n",
            "  Val   Loss: 1.6599 | Val   Acc: 0.3457\n",
            "  Loss Gap:   0.0098 | Acc  Gap:  -0.0042\n",
            "Epoch 16/20\n",
            "  Train Loss: 1.6594 | Train Acc: 0.3488\n",
            "  Val   Loss: 1.6530 | Val   Acc: 0.3553\n",
            "  Loss Gap:   0.0064 | Acc  Gap:  -0.0065\n",
            "Epoch 17/20\n",
            "  Train Loss: 1.6523 | Train Acc: 0.3557\n",
            "  Val   Loss: 1.6786 | Val   Acc: 0.3340\n",
            "  Loss Gap:   -0.0263 | Acc  Gap:  0.0217\n",
            "Epoch 18/20\n",
            "  Train Loss: 1.6453 | Train Acc: 0.3565\n",
            "  Val   Loss: 1.6393 | Val   Acc: 0.3579\n",
            "  Loss Gap:   0.0060 | Acc  Gap:  -0.0014\n",
            "Epoch 19/20\n",
            "  Train Loss: 1.6420 | Train Acc: 0.3555\n",
            "  Val   Loss: 1.6409 | Val   Acc: 0.3568\n",
            "  Loss Gap:   0.0011 | Acc  Gap:  -0.0013\n",
            "Epoch 20/20\n",
            "  Train Loss: 1.6356 | Train Acc: 0.3617\n",
            "  Val   Loss: 1.6514 | Val   Acc: 0.3429\n",
            "  Loss Gap:   -0.0158 | Acc  Gap:  0.0188\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20250530_171029-uxv5ud0o/files/decomposed_eval_model.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.4 Trining FC_4"
      ],
      "metadata": {
        "id": "wVLgAFmjME3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import wandb\n",
        "\n",
        "# === 1. WANDB INIT ===\n",
        "wandb.init(project=\"ML_4\", entity=\"nkhar21-student\", name=\"FC_4\")\n",
        "\n",
        "# === 2. CONFIG ===\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "learning_rate = 0.005  # changed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === 3. MODEL (4 hidden layers) ===\n",
        "input_dim = 48 * 48\n",
        "hidden1 = 512\n",
        "hidden2 = 256\n",
        "hidden3 = 128\n",
        "hidden4 = 64\n",
        "output_dim = 7\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(input_dim, hidden1),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden1, hidden2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden2, hidden3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden3, hidden4),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden4, output_dim),\n",
        ")\n",
        "model.to(device)\n",
        "wandb.watch(model)\n",
        "\n",
        "# === 4. LOSS + OPTIMIZER ===\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# === 5. TRAINING LOOP ===\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = evaluate_model(x_train, y_train, model, loss_fn, device, batch_size, train_mode=True)\n",
        "    val_loss, val_acc = evaluate_model(x_val, y_val, model, loss_fn, device, batch_size, train_mode=False)\n",
        "\n",
        "    # Overfitting metrics\n",
        "    loss_gap = train_loss - val_loss\n",
        "    acc_gap = train_acc - val_acc\n",
        "    loss_ratio = train_loss / val_loss if val_loss != 0 else float(\"inf\")\n",
        "    acc_ratio = train_acc / val_acc if val_acc != 0 else float(\"inf\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
        "    print(f\"  Loss Gap:   {loss_gap:.4f} | Acc  Gap:  {acc_gap:.4f}\")\n",
        "    print(f\"  Loss Ratio: {loss_ratio:.4f} | Acc Ratio: {acc_ratio:.4f}\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "        \"loss_gap\": loss_gap,\n",
        "        \"acc_gap\": acc_gap,\n",
        "        \"loss_ratio\": loss_ratio,\n",
        "        \"acc_ratio\": acc_ratio,\n",
        "    })\n",
        "\n",
        "# === 6. SAVE MODEL ===\n",
        "torch.save(model.state_dict(), \"decomposed_eval_model.pth\")\n",
        "wandb.save(\"decomposed_eval_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4-C8Cj_AMHnu",
        "outputId": "8aca2b06-dd0c-47cf-ca82-1bf196cc6539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc_gap</td><td>▁▄▄▄▄▄▅▂▄▆▅█▃▄▃▃▇▄▄▆</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss_gap</td><td>█▄▄▄▄▄▄▄▅▃▄▁▄▄▄▄▂▄▄▃</td></tr><tr><td>train_accuracy</td><td>▁▂▂▂▂▃▃▄▅▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▆▆▆▆▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▂▂▅▅▄▆▄▇▆▇█▆██▇</td></tr><tr><td>val_loss</td><td>██▇▇▇▆▆▅▄▄▃▄▃▂▂▂▃▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc_gap</td><td>0.01882</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>loss_gap</td><td>-0.01577</td></tr><tr><td>train_accuracy</td><td>0.36174</td></tr><tr><td>train_loss</td><td>1.63563</td></tr><tr><td>val_accuracy</td><td>0.34291</td></tr><tr><td>val_loss</td><td>1.6514</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">FC_1</strong> at: <a href='https://wandb.ai/nkhar21-student/ML_4/runs/uxv5ud0o' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/uxv5ud0o</a><br> View project at: <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250530_171029-uxv5ud0o/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250530_171505-wmvuqj7a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nkhar21-student/ML_4/runs/wmvuqj7a' target=\"_blank\">FC_4</a></strong> to <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nkhar21-student/ML_4' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nkhar21-student/ML_4/runs/wmvuqj7a' target=\"_blank\">https://wandb.ai/nkhar21-student/ML_4/runs/wmvuqj7a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "  Train Loss: 1.9079 | Train Acc: 0.2339\n",
            "  Val   Loss: 1.8804 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0275 | Acc  Gap:  -0.0174\n",
            "  Loss Ratio: 1.0146 | Acc Ratio: 0.9307\n",
            "Epoch 2/20\n",
            "  Train Loss: 1.8581 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8366 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0214 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0117 | Acc Ratio: 1.0000\n",
            "Epoch 3/20\n",
            "  Train Loss: 1.8260 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8167 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0092 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0051 | Acc Ratio: 1.0000\n",
            "Epoch 4/20\n",
            "  Train Loss: 1.8156 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8121 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0035 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0019 | Acc Ratio: 1.0000\n",
            "Epoch 5/20\n",
            "  Train Loss: 1.8129 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8105 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0024 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0013 | Acc Ratio: 1.0000\n",
            "Epoch 6/20\n",
            "  Train Loss: 1.8115 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8093 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0023 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0012 | Acc Ratio: 1.0000\n",
            "Epoch 7/20\n",
            "  Train Loss: 1.8102 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8079 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0022 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0012 | Acc Ratio: 1.0000\n",
            "Epoch 8/20\n",
            "  Train Loss: 1.8088 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8069 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0018 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0010 | Acc Ratio: 1.0000\n",
            "Epoch 9/20\n",
            "  Train Loss: 1.8074 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8050 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0024 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0013 | Acc Ratio: 1.0000\n",
            "Epoch 10/20\n",
            "  Train Loss: 1.8058 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8036 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0022 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0012 | Acc Ratio: 1.0000\n",
            "Epoch 11/20\n",
            "  Train Loss: 1.8041 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.8019 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0022 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0012 | Acc Ratio: 1.0000\n",
            "Epoch 12/20\n",
            "  Train Loss: 1.8021 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.7999 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0022 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0012 | Acc Ratio: 1.0000\n",
            "Epoch 13/20\n",
            "  Train Loss: 1.7998 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.7973 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0025 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0014 | Acc Ratio: 1.0000\n",
            "Epoch 14/20\n",
            "  Train Loss: 1.7971 | Train Acc: 0.2513\n",
            "  Val   Loss: 1.7946 | Val   Acc: 0.2513\n",
            "  Loss Gap:   0.0026 | Acc  Gap:  0.0000\n",
            "  Loss Ratio: 1.0014 | Acc Ratio: 1.0000\n",
            "Epoch 15/20\n",
            "  Train Loss: 1.7939 | Train Acc: 0.2514\n",
            "  Val   Loss: 1.7912 | Val   Acc: 0.2515\n",
            "  Loss Gap:   0.0027 | Acc  Gap:  -0.0001\n",
            "  Loss Ratio: 1.0015 | Acc Ratio: 0.9995\n",
            "Epoch 16/20\n",
            "  Train Loss: 1.7899 | Train Acc: 0.2529\n",
            "  Val   Loss: 1.7889 | Val   Acc: 0.2524\n",
            "  Loss Gap:   0.0010 | Acc  Gap:  0.0006\n",
            "  Loss Ratio: 1.0006 | Acc Ratio: 1.0023\n",
            "Epoch 17/20\n",
            "  Train Loss: 1.7854 | Train Acc: 0.2549\n",
            "  Val   Loss: 1.7839 | Val   Acc: 0.2522\n",
            "  Loss Gap:   0.0014 | Acc  Gap:  0.0028\n",
            "  Loss Ratio: 1.0008 | Acc Ratio: 1.0109\n",
            "Epoch 18/20\n",
            "  Train Loss: 1.7799 | Train Acc: 0.2581\n",
            "  Val   Loss: 1.7767 | Val   Acc: 0.2567\n",
            "  Loss Gap:   0.0032 | Acc  Gap:  0.0014\n",
            "  Loss Ratio: 1.0018 | Acc Ratio: 1.0055\n",
            "Epoch 19/20\n",
            "  Train Loss: 1.7730 | Train Acc: 0.2650\n",
            "  Val   Loss: 1.7686 | Val   Acc: 0.2607\n",
            "  Loss Gap:   0.0044 | Acc  Gap:  0.0043\n",
            "  Loss Ratio: 1.0025 | Acc Ratio: 1.0166\n",
            "Epoch 20/20\n",
            "  Train Loss: 1.7641 | Train Acc: 0.2720\n",
            "  Val   Loss: 1.7581 | Val   Acc: 0.2682\n",
            "  Loss Gap:   0.0060 | Acc  Gap:  0.0038\n",
            "  Loss Ratio: 1.0034 | Acc Ratio: 1.0140\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20250530_171505-wmvuqj7a/files/decomposed_eval_model.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[3].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75i1G8KfNFtR",
        "outputId": "aa655181-4f2a-4a05-f0df-164d70a18dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.078431375)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V_NiDpLN2G1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oZ0xu9t6NIpK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}