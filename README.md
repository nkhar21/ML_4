# ML_4

0.  შესავალი
    მოცემულ კეგლის competition-ში მოცემულია ადამიანის სახეების სურათი, რომლებიც 7 სხვადასხვა ემოციას გამოხატავს მიმიკით.
    ესენია: სიბრაზე, ზიზღი, შიში, სიხარული, სევდა, გაოცება და ნეიტრალური.
    ჩვენი ამოცანაა შევქმნათ მოდელი, რომელიც ამ ემოციებს ამოიცნობს.

    შევქმენი 3 .ipynb ფაილი, რომლებშიც ნელნელა გავაუმჯობესე და გავართულე მოდელები.

    ყველა ფაილში გავაკეთე პატარა პრეპროცესინგი, სადაც x_train გადავიყვანე (N,48,48,1) განზომილებაში,
    ანუ 48x48 Grayscale სურათში, სადაც თითოეული სურათის პიქსელის მნიშვნელობა 0-დან 1-მდეა ნორმალიზებული.
    მიღებული დატა გავყავი ვალიდაციისა და ტრეინის სეტად 80/20, random_seed = 42 კონსისტენტურობისთვის.

    Wandb-ზე ვლგავდი შემდეგ მეტრიკებს: ვალიდაციის/ტრენინგის accuracყ და loss, მათი სხვაობები და ფარდობები.
    ვლოგავდი ასევე თითეული მოდელის პარამეტრებსა და კონფიგურაციებს.

    შემდეგ ნაწილში მოდელების აღწერისას, თუ არ მოვიხსენიე მოდელის კონკრეტული არქიტექტურა/პარამეტრები დელატებში,
    ესეიგი მის წინა მოდელის მსგავსია.

2. Facial_Recognition_Basic.ipynb - გავერკვიე, როგორ გამემართა გარემო (kaggle/wandb) და გავტესტე რამდენიმე FC მოდელი

   მოდელი 1 - First_Basic_FC
     არქიტექტურა: 48x48x1 -> flattern (რადგან FC) -> წრფივი 48*48 -> ReLU -> წრფივი 7*48.
     loss_fn: Cross Entropy - ყველა მომდევნო მოდელში ამას ვიყენებ
     optimizer: SGD - ამ ფაილის მოდელებში ყველგან ამას ვიყენებ
     learning_rate: 0.01
     epochs: 10
     train, validation accuracy: 0.3637 / 0.3624

   მოდელი 2 - Decomposed_Eval_Model - უფრო ღრმა გავხადე
     არქიტექტურა: დავამატე 2 წრფივი hidden layer - 48*4 და 48 სიგრძის.
       მეგონა მოდელის გაღრმავებით გავაუმჯობესებდი შედეგს, მაგრად თითქმის იგივე შედეგები მივიღე,
       მეტიც, ცოტა უფრო ცუდი შედეგი მივიღე.

   მოდელი 3  - FC_1 გავზარდე ეპოქების რაოდენობები (20-მდე), შევამცირე lr და hidden layer-ების ზომები, თუმცა ამ მოდელმაც
   თითქმის იდენტური შედეგი დადო.
   train, validation accuracy: 0.3617 / 0.3429

   მოდელი 4 - FC_4 - აქ ბევრი არ შემიცვლია გარდა lr = 0.005.
     ეს ცვლილება ძალიან ცუდი გამოდგა, რადგან თითქმის ვერაფერი ისწავლა მოდელმა და 20 ეპოქაში 0.2513-დან 0.2682 ვალიდაციაზე
     ძლივს ავიდა.

   ზემოთ ჩამოთვლილ მოდელებში overfit არ იყო. ამიტომ არ დამიმატებია რეგულარიზაციები. თუმცა აშკარა იყო რომ შედეგი არ უმჯობესდებოდა. 
   აქ გადავწყვიტე, რომ რაც არ უნდა მექნა FC მოდელებით მაღალ შედეგზე ვერ გავიდოდი და გადავედი კონვოლუციურ ქსელებზე.

3. FER_CNN_1.ipynb - კონვოლუციური ქსელები

   მოდელი 1
     არქიტექტურა: 3 conv2d (channels = [8, 16, 32] stride=padding=1), 2 FC (256 -> 128)
     optimizer: Adam
     lr: 0.01
     epochs: 20
     lr ძალიან დაბალი გამოდგა, ამ არქიტექტურისთვის და მოდელმა საერთოდ ვერაფერი ისწავლა 20 ეპოქის განმავლობაში.

   მოდელი 2 - უბრალოდ lr = 0.001 შევცვალე და ძალიან გააუმჯობესა
     train, validation accuracy: 0.9965 / 0.4734
     თუმცა უდიდესი overfit - საჭიროა გენერალიზაცია (რეგულარიზაცია/დროპაუთი)

   მოდელი 3 - დავამატე dropout overfit-ის საშველად.
     epochs: 10
     გავტესტე სხვადასხვა პარამეტრები - dropout_rates = [0.0, 0.2, 0.4, 0.5]
     საუკეთესო გამოდგა 0.5
     train, validation accuracy: 0.7833 / 0.4934
     საგრძნობლად შემცირდა overfit და ვალიდაციაზეც გაუმჯობესდა. თუმცა მაინცაა overfit, ამიტომ დავამატე pooling.

   მოდელი 4 - (2,2) ჯობდა (3,3) max pool-ს.
     გაუმჯობესდა კიდევ შედეგი
     train, validation accuracy: 0.5003 / 0.4956 - აღარაა overfit. ცოტა underfit, რადგან ტითქმის იდენტურია ეს ორი.
   


   
