# ML_4
wandb project: https://wandb.ai/nkhar21-student/ML_4

0.  შესავალი
    მოცემულ კეგლის competition-ში მოცემულია ადამიანის სახეების სურათი, რომლებიც 7 სხვადასხვა ემოციას გამოხატავს მიმიკით.
    ესენია: სიბრაზე, ზიზღი, შიში, სიხარული, სევდა, გაოცება და ნეიტრალური.
    ჩვენი ამოცანაა შევქმნათ მოდელი, რომელიც ამ ემოციებს ამოიცნობს.

    შევქმენი 3 .ipynb ფაილი, რომლებშიც ნელნელა გავაუმჯობესე და გავართულე მოდელები.

    ყველა ფაილში გავაკეთე პატარა პრეპროცესინგი, სადაც x_train გადავიყვანე (N,48,48,1) განზომილებაში,
    ანუ 48x48 Grayscale სურათში, სადაც თითოეული სურათის პიქსელის მნიშვნელობა 0-დან 1-მდეა ნორმალიზებული.
    მიღებული დატა გავყავი ვალიდაციისა და ტრეინის სეტად 80/20, random_seed = 42 კონსისტენტურობისთვის.

    Wandb-ზე ვლგავდი შემდეგ მეტრიკებს: ვალიდაციის/ტრენინგის accuracყ და loss, მათი სხვაობები და ფარდობები.
    ვლოგავდი ასევე თითეული მოდელის პარამეტრებსა და კონფიგურაციებს.

    შემდეგ ნაწილში მოდელების აღწერისას, თუ არ მოვიხსენიე მოდელის კონკრეტული არქიტექტურა/პარამეტრები დელატებში,
    ესეიგი მის წინა მოდელის მსგავსია.

2. Facial_Recognition_Basic.ipynb - გავერკვიე, როგორ გამემართა გარემო (kaggle/wandb) და გავტესტე რამდენიმე FC მოდელი

   მოდელი 1 - First_Basic_FC
     არქიტექტურა: 48x48x1 -> flattern (რადგან FC) -> წრფივი 48*48 -> ReLU -> წრფივი 7*48.
     loss_fn: Cross Entropy - ყველა მომდევნო მოდელში ამას ვიყენებ
     optimizer: SGD - ამ ფაილის მოდელებში ყველგან ამას ვიყენებ
     learning_rate: 0.01
     epochs: 10
     train, validation accuracy: 0.3637 / 0.3624

   მოდელი 2 - Decomposed_Eval_Model - უფრო ღრმა გავხადე
     არქიტექტურა: დავამატე 2 წრფივი hidden layer - 48*4 და 48 სიგრძის.
       მეგონა მოდელის გაღრმავებით გავაუმჯობესებდი შედეგს, მაგრად თითქმის იგივე შედეგები მივიღე,
       მეტიც, ცოტა უფრო ცუდი შედეგი მივიღე.

   მოდელი 3  - FC_1 გავზარდე ეპოქების რაოდენობები (20-მდე), შევამცირე lr და hidden layer-ების ზომები, თუმცა ამ მოდელმაც
   თითქმის იდენტური შედეგი დადო.
   train, validation accuracy: 0.3617 / 0.3429

   მოდელი 4 - FC_4 - აქ ბევრი არ შემიცვლია გარდა lr = 0.005.
     ეს ცვლილება ძალიან ცუდი გამოდგა, რადგან თითქმის ვერაფერი ისწავლა მოდელმა და 20 ეპოქაში 0.2513-დან 0.2682 ვალიდაციაზე
     ძლივს ავიდა.

   ზემოთ ჩამოთვლილ მოდელებში overfit არ იყო. ამიტომ არ დამიმატებია რეგულარიზაციები. თუმცა აშკარა იყო რომ შედეგი არ უმჯობესდებოდა. 
   აქ გადავწყვიტე, რომ რაც არ უნდა მექნა FC მოდელებით მაღალ შედეგზე ვერ გავიდოდი და გადავედი კონვოლუციურ ქსელებზე.

3. FER_CNN_1.ipynb - კონვოლუციური ქსელები

   მოდელი 1
     არქიტექტურა: 3 conv2d (channels = [8, 16, 32] stride=padding=1), 3 FC (last_channel_size*48*48 -> 256 -> 128)
     optimizer: Adam
     lr: 0.01
     epochs: 20
     lr ძალიან დაბალი გამოდგა, ამ არქიტექტურისთვის და მოდელმა საერთოდ ვერაფერი ისწავლა 20 ეპოქის განმავლობაში.

   მოდელი 2 - უბრალოდ lr = 0.001 შევცვალე და ძალიან გააუმჯობესა
     train, validation accuracy: 0.9965 / 0.4734
     თუმცა უდიდესი overfit - საჭიროა გენერალიზაცია (რეგულარიზაცია/დროპაუთი)

   მოდელი 3 - დავამატე dropout overfit-ის საშველად.
     epochs: 10
     გავტესტე სხვადასხვა პარამეტრები - dropout_rates = [0.0, 0.2, 0.4, 0.5]
     საუკეთესო გამოდგა 0.5
     train, validation accuracy: 0.7833 / 0.4934
     საგრძნობლად შემცირდა overfit და ვალიდაციაზეც გაუმჯობესდა. თუმცა მაინცაა overfit, ამიტომ დავამატე pooling.

   მოდელი 4 - (2,2) ჯობდა (3,3) max pool-ს.
     გაუმჯობესდა კიდევ შედეგი
     train, validation accuracy: 0.5003 / 0.4956 - აღარაა overfit. ცოტა underfit, რადგან ტითქმის იდენტურია ეს ორი.

   მოდელი 5 - წინა მოდელის გაუმჯობესება:
       გავზარდე channels
       შევამცირე dropout - 0.5-დან 0.3 (ეს ჯობდა) და 0.4 
       შევამცირე lr
       train, validation accuracy: 0.82814 / 0.55834 - შედეგი უკეთესია მაგრამ დიდი overfit.

   მოდელი 6 - დავამატე batchnorm
       სამივე conv2d-ს მერე ბაჩნორმი [32, 64, 128]
       dropout: 0.25
       lr: 0.001
       epochs: 20
       train, validation accuracy: 0.84504 / 0.58917 - შედეგი უკეთესია, მაგრამ ისევაა overfit.

   შემდეგ დავტუნე lr, ვცადე Groupnorm, Layernorm.
       სხვა ნორმალიზაციებმა საგრძნობლად უარესი შედეგი მომცა - 0.5-ზე მეტი არ ჰქონდათ ვალიდაციაზე,
       მიუხედავად იმისა, რომ საკმაოდ გააუმჯობა overfit. ამიტომ გადავწყვიტე რომ batchnorm არის საუკეთესო.
       შემეძლო სხვა მოდელის არქიტექტურებიც გამომეცადა, მაგრამ როგორც წინა დავალებაში ვნახე batchnorm ჯობს ხოლმე ყველას.
       layernorm ცოტა პატარა მოდელზე შეიძლება უკეთესი იყოს, მაგრამ fer2013-ს არ გამოადგება პატარა მოდელი.

   მოდელი 7 - დავამატე scheduler, weight decay, early stopping და დავტუნე პარამეტრები. საუკეთესო მოდელი იყო:
       epochs: 30
       scheduler: ReduceLROnPlateau - თუმცა თითქმის არ გამოუყენებია
       Weight Decay: 0.00096
       Early stopping
       train, validation accuracy: 0.86581 / 0.57419 - თუმცა წინას ვერ აჯობა

   მოდელი 8 - ვცადე სხვადასხვა არქიტექტურები შემდეგი პარამეტრებით:
       channels, kernel_size, strides, paddings.
       საუკეთესო მოდელს თითქმის იდენტური პარამეტრები ჰქონდა რაც მოდელ 6-ს.
       channels=[32, 64, 128]
       kernel_sizes=[3, 3, 3]
       strides=[1, 1, 1]
       paddings=[1, 1, 1]
       lr=0.001,
       dropout_rate=0.4,
       weight_decay=1e-4,
       epochs=30
       train, validation accuracy: 0.71315 / 0.58481 - თითქმის იდენტურია მოდელი 6-ის, თუმცა ნაკლები overfit.

   აქ შევწყვიტე ეს ფაილი, რადგან 0.59-მდე ვერანაირად ვეღარ ავდიოდი ბევრი მცდელობების მიუხედავად.
   ამიტომ მოდელს დავამატე data augmentation შემდეგ ფაილში.


3. FER_Data_Augmentation.ipynb - კონვოლუციური ქსელები


    
